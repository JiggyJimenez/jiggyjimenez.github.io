{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72885e03",
   "metadata": {},
   "source": [
    "# Assignment 3 - Transformer Implemention with Andrej Karpathy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a752c7",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8bb36",
   "metadata": {},
   "source": [
    "1.\tWatch the following tutorial by Andrej Karpathy (https://twitter.com/karpathy):\n",
    "        a.\thttps://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "        b.\tAs you are watching, run the code yourself (preferably on a fresh notebook).\n",
    "        c.\tYou can download a copy of his notebook from here:\n",
    "            i.\thttps://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing\n",
    "            ii.\tMake sure you can run this notebook from start to finish!\n",
    "        d.\tYou can also check out a cleaner version of the code here:\n",
    "            i.\thttps://github.com/karpathy/ng-video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e6a48",
   "metadata": {},
   "source": [
    "## What is a language model?\n",
    "\n",
    "A language model is an advanced computer program trained on vast amounts of text data. It can understand and generate human language, making it a valuable tool for various applications. By analyzing patterns and relationships in language, it predicts words, completes sentences, and generates coherent text. Language models improve language translation, aid in writing tasks, and power voice assistants and chatbots. They enhance our interactions with technology and enable more efficient communication in the digital age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a91a1d",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e8b7be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T08:50:57.487801Z",
     "start_time": "2023-06-10T08:50:56.964096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-10 08:50:57--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-06-10 08:50:57 (44.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetching dataset from Karpathy's repo\n",
    "\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3e2aa",
   "metadata": {},
   "source": [
    "In this project, we're working with a special dataset that features a handpicked selection of works by none other than the legendary playwright, William Shakespeare. It's like diving into a treasure trove of scripts from various plays and literary masterpieces penned by Shakespeare himself. This dataset holds a special place in the heart of Karpathy, one of the brilliant minds in the field, and it's a popular choice for tackling all sorts of exciting natural language processing (NLP) challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bb81c",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9c2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T15:07:45.196588Z",
     "start_time": "2023-05-26T15:07:45.192140Z"
    }
   },
   "source": [
    "Here's a breakdown of the key steps involved in this process:\n",
    "\n",
    "1. First, we create a sorted list of unique characters, which serves as a reference for our vocabulary. It helps us keep track of all the distinct characters present in our data.\n",
    "\n",
    "2. Next, we determine the size of the vocabulary, which in turn sets the embedding size. This step ensures that our model has the right dimensions to handle the data effectively.\n",
    "\n",
    "3. We create two dictionaries: `stoi` (string to integers) and `itos` (integer to string). These dictionaries establish a mapping between characters and integers, allowing us to easily convert text into numerical representations and vice versa.\n",
    "\n",
    "4. The `encode` and `decode` functions make use of these dictionaries. The `encode` function takes a string as input and converts it into a list of corresponding integers using the `stoi` dictionary. On the other hand, the `decode` function takes a list of integers and converts it back into a string using the `itos` dictionary.\n",
    "\n",
    "5. Finally, we split the dataset into train and test sets based on the length of the encoded data. The training set contains 90% of the data, while the test set contains the remaining 10%. This split allows us to evaluate the performance of our model on unseen data.\n",
    "\n",
    "These steps are essential for setting up the necessary mappings between characters and integers, providing functions for encoding and decoding, and preparing the data for further processing and modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c4e446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:17:27.532044Z",
     "start_time": "2023-06-10T15:17:27.517351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "# Loading the content of the file and counting total characters\n",
    "\n",
    "with open('input.txt', 'r', encoding='utf-8') as f: \n",
    "    text = f.read()\n",
    "print(f'len of dataset in characters: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e39baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:17:28.212910Z",
     "start_time": "2023-06-10T15:17:28.206143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Viewing first 1000 lines of the dataset\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f1f3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:17:28.684964Z",
     "start_time": "2023-06-10T15:17:28.652638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Get all unique characters sort it and its total len\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a354ff0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:17:29.455937Z",
     "start_time": "2023-06-10T15:17:29.444030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43, 2]\n",
      "hi there!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Initialization of String-to-Integer and Integer-to-String Dictionaries: \n",
    "    Initializing dictionaries to map each character to its corresponding index \n",
    "    and each index to its corresponding character. \n",
    "\n",
    "    Definition of encode and decode functions: \n",
    "    Defining functions to convert the text and list of integers into their \n",
    "    respective indexed values.\n",
    "\"\"\"\n",
    "\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "iots = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([iots[i] for i in l])\n",
    "\n",
    "print(encode(\"hi there!\"))\n",
    "print(decode(encode(\"hi there!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2716130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:17:31.777129Z",
     "start_time": "2023-06-10T15:17:29.836206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "#Encoding of the whole dataset and conversion to tensor object\n",
    "\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8d5923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:30:12.770199Z",
     "start_time": "2023-06-10T15:30:12.763502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train (90%) and test (10%) splits.\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1965b2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:30:18.238137Z",
     "start_time": "2023-06-10T15:30:18.219485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We never gonna feed the entire text all at once\n",
    "# Only work with chunks of the dataset through maximum length -- block size\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c0cc3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:30:52.092243Z",
     "start_time": "2023-06-10T15:30:52.079575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce6c2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:40:16.950830Z",
     "start_time": "2023-06-10T15:40:16.925391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the taget: 43\n",
      "when input is [24, 43] the taget: 58\n",
      "when input is [24, 43, 58] the taget: 5\n",
      "when input is [24, 43, 58, 5] the taget: 57\n",
      "when input is [24, 43, 58, 5, 57] the taget: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the taget: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the taget: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the taget: 39\n",
      "when input is [44] the taget: 53\n",
      "when input is [44, 53] the taget: 56\n",
      "when input is [44, 53, 56] the taget: 1\n",
      "when input is [44, 53, 56, 1] the taget: 58\n",
      "when input is [44, 53, 56, 1, 58] the taget: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the taget: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the taget: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the taget: 1\n",
      "when input is [52] the taget: 58\n",
      "when input is [52, 58] the taget: 1\n",
      "when input is [52, 58, 1] the taget: 58\n",
      "when input is [52, 58, 1, 58] the taget: 46\n",
      "when input is [52, 58, 1, 58, 46] the taget: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the taget: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the taget: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the taget: 46\n",
      "when input is [25] the taget: 17\n",
      "when input is [25, 17] the taget: 27\n",
      "when input is [25, 17, 27] the taget: 10\n",
      "when input is [25, 17, 27, 10] the taget: 0\n",
      "when input is [25, 17, 27, 10, 0] the taget: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the taget: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the taget: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the taget: 39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Karpathy demonstrated and explained how the dataset is prepared for \n",
    "    training explained here that each sequence of data has maximimum of 8 \n",
    "    tokens as the block_size is 8 and 4 rows for each batch. This is shown\n",
    "    as the architecture can process matrices in parallel independent of each\n",
    "    other as we've also discussed in class.\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): #time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the taget: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79285f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:42:50.717785Z",
     "start_time": "2023-06-10T15:42:50.596077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This is the initial version of the BigramLanguageModel, where Karpathy \n",
    "    explained the shapes of B (batch_size), T (sequence length), and C \n",
    "    (channels/vocab_size). We discussed how logits-softmax works, which is the \n",
    "    same explanation we had in class. We also calculated the loss using \n",
    "    cross_entropy when the target is defined, as it measures the dissimilarity \n",
    "    between the predicted probability distribution over classes (our vocabulary) \n",
    "    and the true distribution (target token).\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the BigramLanguageModel.\n",
    "        \n",
    "        Args:\n",
    "            idx (torch.Tensor): Input tensor of shape (B, T) representing the indices of tokens.\n",
    "            targets (torch.Tensor): Target tensor of shape (B, T) representing the indices of target tokens.\n",
    "        \n",
    "        Returns:\n",
    "            logits (torch.Tensor): Logits tensor of shape (B, T, C) representing the predicted scores for each token.\n",
    "            loss (torch.Tensor or None): Loss tensor if targets are provided, else None.\n",
    "        \"\"\"\n",
    "        logits = self.token_embedding_table(idx)  # (B, T, C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Generate new tokens based on the input sequence.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): Input tensor of shape (B, T) representing the indices of tokens.\n",
    "            max_new_tokens (int): Maximum number of new tokens to generate.\n",
    "\n",
    "        Returns:\n",
    "            idx (torch.Tensor): Generated tensor of shape (B, T+max_new_tokens) representing the updated sequence.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "print(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "# Initiate idx with a 1,1 tensor to kick_off the generation of 100 new tokens\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b264c00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:43:07.740588Z",
     "start_time": "2023-06-10T15:43:07.733811Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f63db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:44:17.534309Z",
     "start_time": "2023-06-10T15:44:02.054576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6380467414855957\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dbbf8fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:44:25.170412Z",
     "start_time": "2023-06-10T15:44:25.087925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gCv,XatYgGf bsAm'PADUvk!ukOET;humVz&fsJgCJMERSTMkW.IV;Bk't?ERN q-.g Ybrw'BSKd&YNYHA,iy ixl;gRnpGNIIgCH&'woc; ;AUVlxagGJM\n",
      "oKkWNf?EH-\n",
      ":CxOhPQFllSP!BOjKBBAQymyqMliPdFot;:q-wJ&\n",
      "fxa!BHBiabvvKIVzM:CAWheht$g\n",
      "GFd&jFnDCEXDuUVKootgUGF!aPxTph:C mOy.d?Cu!?z3SgYUK:CIU?mnlV&y.nQ'd zfs$IJzPO Ax; zwf-imlatNHA.ZGlysuRPyiyieH'X'zLoocUztowMcf'myeD.Dqmyk$. dsnlivRCxnnmasxiRSm,FERM?lIEKaPvriqZY?nQlcR: OMH-Ku-la!SKNT?Rj?d,i.,SP swbcObZpYUD3De,ir nsfRju-wU,\n",
      "Fk-?wfritysV;.nQ?OgQwoT&T:qKAUz-thzkptyFd,sBORp'Ard\n",
      "oCVJjeUGN\n"
     ]
    }
   ],
   "source": [
    "# Quality is still pretty bad but better than the initial output\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f0315b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:44:53.217697Z",
     "start_time": "2023-06-10T15:44:53.198884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8991c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:45:04.297541Z",
     "start_time": "2023-06-10T15:45:04.281339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b17108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:46:29.897181Z",
     "start_time": "2023-06-10T15:46:29.886288Z"
    }
   },
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d6dd96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:46:59.603893Z",
     "start_time": "2023-06-10T03:46:59.593189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]]) tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x #(B, T, T) @ (B, T, C) -----> (B, T, C)\n",
    "print(torch.allclose(xbow, xbow2))\n",
    "print(xbow[0], xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "239794ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:47:13.263236Z",
     "start_time": "2023-06-10T03:47:13.248086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]]) tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "\n",
    "print(torch.allclose(xbow, xbow3))\n",
    "print(xbow[0], xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4619f790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:47:35.413683Z",
     "start_time": "2023-06-10T03:47:35.394369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4d7cb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:47:45.001968Z",
     "start_time": "2023-06-10T03:47:44.989279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0460792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:12.000484Z",
     "start_time": "2023-06-10T03:48:11.994097Z"
    }
   },
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92dbe617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:12.537011Z",
     "start_time": "2023-06-10T03:48:12.529586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26bebcd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:13.186650Z",
     "start_time": "2023-06-10T03:48:13.178578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc0693b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:14.083516Z",
     "start_time": "2023-06-10T03:48:14.073641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b827d1e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:16.947492Z",
     "start_time": "2023-06-10T03:48:16.937490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "376605d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T03:48:22.242804Z",
     "start_time": "2023-06-10T03:48:22.209804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1335, -0.1059, -0.3824,  ..., -1.3422, -0.1971,  0.8795],\n",
       "        [-0.0353, -0.7439, -0.3371,  ..., -0.6276, -0.4846,  0.4556],\n",
       "        [ 0.3069, -1.5010,  1.4898,  ..., -0.6819,  0.9993,  0.8382],\n",
       "        ...,\n",
       "        [-1.6080, -1.6324, -0.7634,  ..., -0.9847,  0.0039, -0.8610],\n",
       "        [-0.2273,  0.0066, -0.2763,  ..., -0.8705, -1.2442, -0.7531],\n",
       "        [ 0.3054, -0.1505, -0.3809,  ..., -1.4962, -0.7711, -1.0681]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "    \"\"\"\n",
    "    Custom implementation of Layer Normalization for 1D input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of LayerNorm1d.\n",
    "        \"\"\"\n",
    "        xmean = x.mean(1, keepdim=True)  # Calculate batch mean\n",
    "        xvar = x.var(1, keepdim=True)  # Calculate batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # Normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Return the parameters of the LayerNorm1d module.\n",
    "        \"\"\"\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100)  # Batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "print(x.shape)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e195d0",
   "metadata": {},
   "source": [
    "## What is self-attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372aa615",
   "metadata": {},
   "source": [
    "Self-attention is a mechanism used in deep learning models, particularly in natural language processing. It allows the model to weigh the importance of different elements in a sequence by learning their relationships. Unlike traditional models, self-attention enables each element to directly consider all other elements, capturing long-range dependencies effectively. It works by computing attention scores between elements based on their queries and keys, and using these scores to combine the values and create a representation. This helps the model understand contextual information and identify important elements within the sequence. Self-attention has been successful in tasks like machine translation and text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9ddfb",
   "metadata": {},
   "source": [
    "## Compare and contrast the concept of attention, self-attention, and cross-attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb961bdd",
   "metadata": {},
   "source": [
    "Attention: It is a mechanism that assigns weights to different elements in a sequence based on their relevance to a specific element. It allows the model to focus on important elements while processing the sequence.\n",
    "\n",
    "Self-attention: It is a specific type of attention mechanism where elements within the same sequence attend to each other. Each element computes its own attention weights based on its relationships with other elements in the sequence. Self-attention helps capture dependencies and long-range dependencies within the sequence.\n",
    "\n",
    "Cross-attention: It is an extension of attention where elements from one sequence attend to elements from another sequence. This mechanism is useful when dealing with tasks that involve multiple sequences or when capturing relationships between different parts of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23d43c",
   "metadata": {},
   "source": [
    "## What is multi-head attention? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f1f1e0",
   "metadata": {},
   "source": [
    "In deep learning, \"multi-head attention\" refers to the concept of having multiple attention mechanisms, called \"heads,\" working independently to focus on different parts of the input sequence. It extends the basic attention mechanism by using multiple heads simultaneously, each learning different representations of the input. The outputs from the individual heads are combined to create a final representation.\n",
    "\n",
    "This technique allows the model to capture diverse types of information and dependencies in the input. By employing multiple heads, the model can attend to different aspects or perspectives of the input at the same time, enabling it to extract meaningful information and capture complex relationships. Multi-head attention provides the model with the ability to leverage various attention patterns and learn more expressive representations. It has proven effective in various tasks, such as machine translation and language modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a71150",
   "metadata": {},
   "source": [
    "## What is a transformer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d31598",
   "metadata": {},
   "source": [
    "A transformer is a powerful deep learning model designed for natural language processing tasks. It uses self-attention to understand the relationships between words in a sentence, allowing it to consider context and dependencies effectively. Unlike traditional models, transformers can process input in parallel, making them efficient. They have achieved impressive results in tasks like translation, summarization, and question answering, transforming the field of NLP with their ability to capture context and handle long-range dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5a064",
   "metadata": {},
   "source": [
    "### Transformer Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffeaad2",
   "metadata": {},
   "source": [
    "### Setting the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "829100e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T16:42:06.589503Z",
     "start_time": "2023-06-10T16:42:06.544006Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def nano_GPT (batch_size=16, block_size=32, max_iters=5000, eval_interval=100,\n",
    "              learning_rate=1e-3, eval_iters=200, n_embd=64, n_head=4,\n",
    "              n_layer=4, dropout=0.0):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch.manual_seed(1337)\n",
    "\n",
    "    # wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "    with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # here are all the unique characters that occur in this text\n",
    "    chars = sorted(list(set(text)))\n",
    "    vocab_size = len(chars)\n",
    "    # create a mapping from characters to integers\n",
    "    stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "    itos = { i:ch for i,ch in enumerate(chars) }\n",
    "    encode = lambda s: [stoi[c] for c in s] \n",
    "    decode = lambda l: ''.join([itos[i] for i in l]) \n",
    "\n",
    "    # Train and test splits\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "    n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "    train_data = data[:n]\n",
    "    val_data = data[n:]\n",
    "\n",
    "    # data loading\n",
    "    def get_batch(split):\n",
    "        # generate a small batch of data of inputs x and targets y\n",
    "        data = train_data if split == 'train' else val_data\n",
    "        ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "        x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        return x, y\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def estimate_loss():\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out\n",
    "\n",
    "    class Head(nn.Module):\n",
    "        \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "        def __init__(self, head_size):\n",
    "            super().__init__()\n",
    "            self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x):\n",
    "            B,T,C = x.shape\n",
    "            k = self.key(x)   # (B,T,C)\n",
    "            q = self.query(x) # (B,T,C)\n",
    "            # compute attention scores (\"affinities\")\n",
    "            wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "            wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "            wei = self.dropout(wei)\n",
    "            # perform the weighted aggregation of the values\n",
    "            v = self.value(x) # (B,T,C)\n",
    "            out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "            return out\n",
    "\n",
    "    class MultiHeadAttention(nn.Module):\n",
    "        \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "        def __init__(self, num_heads, head_size):\n",
    "            super().__init__()\n",
    "            self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "            self.proj = nn.Linear(n_embd, n_embd)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "            out = self.dropout(self.proj(out))\n",
    "            return out\n",
    "\n",
    "    class FeedFoward(nn.Module):\n",
    "\n",
    "        def __init__(self, n_embd):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_embd, 4 * n_embd),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4 * n_embd, n_embd),\n",
    "                nn.Dropout(dropout),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    class Block(nn.Module):\n",
    "        \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "        def __init__(self, n_embd, n_head):\n",
    "            super().__init__()\n",
    "            head_size = n_embd // n_head\n",
    "            self.sa = MultiHeadAttention(n_head, head_size)\n",
    "            self.ffwd = FeedFoward(n_embd)\n",
    "            self.ln1 = nn.LayerNorm(n_embd)\n",
    "            self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x + self.sa(self.ln1(x))\n",
    "            x = x + self.ffwd(self.ln2(x))\n",
    "            return x\n",
    "\n",
    "    # super simple bigram model\n",
    "    class BigramLanguageModel(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "            self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "            self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "            self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "            self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        def forward(self, idx, targets=None):\n",
    "            B, T = idx.shape\n",
    "            tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "            pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "            x = tok_emb + pos_emb # (B,T,C)\n",
    "            x = self.blocks(x) # (B,T,C)\n",
    "            x = self.ln_f(x) # (B,T,C)\n",
    "            logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "            if targets is None:\n",
    "                loss = None\n",
    "            else:\n",
    "                B, T, C = logits.shape\n",
    "                logits = logits.view(B*T, C)\n",
    "                targets = targets.view(B*T)\n",
    "                loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "            return logits, loss\n",
    "\n",
    "        def generate(self, idx, max_new_tokens):\n",
    "            # idx is (B, T) array of indices in the current context\n",
    "            for _ in range(max_new_tokens):\n",
    "                # crop idx to the last block_size tokens\n",
    "                idx_cond = idx[:, -block_size:]\n",
    "                # get the predictions\n",
    "                logits, loss = self(idx_cond)\n",
    "                # focus only on the last time step\n",
    "                logits = logits[:, -1, :] # becomes (B, C)\n",
    "                # apply softmax to get probabilities\n",
    "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "                # sample from the distribution\n",
    "                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "                # append sampled index to the running sequence\n",
    "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "            return idx\n",
    "\n",
    "    model = BigramLanguageModel()\n",
    "    m = model.to(device)\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "\n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch('train')\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # generate from the model\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b501bd1",
   "metadata": {},
   "source": [
    "## Fine tuning the model with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f559467",
   "metadata": {},
   "source": [
    "### Step 1: Setting baseline/benchmark\n",
    "Executed with just the base parameters from the repository and will be used as the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62000ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T16:48:19.244880Z",
     "start_time": "2023-06-10T16:42:07.916487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M parameters\n",
      "step 0: train loss 4.4116, val loss 4.4022\n",
      "step 100: train loss 2.6568, val loss 2.6670\n",
      "step 200: train loss 2.5090, val loss 2.5058\n",
      "step 300: train loss 2.4194, val loss 2.4335\n",
      "step 400: train loss 2.3505, val loss 2.3569\n",
      "step 500: train loss 2.2965, val loss 2.3129\n",
      "step 600: train loss 2.2410, val loss 2.2500\n",
      "step 700: train loss 2.2047, val loss 2.2186\n",
      "step 800: train loss 2.1635, val loss 2.1868\n",
      "step 900: train loss 2.1238, val loss 2.1503\n",
      "step 1000: train loss 2.1024, val loss 2.1289\n",
      "step 1100: train loss 2.0705, val loss 2.1189\n",
      "step 1200: train loss 2.0396, val loss 2.0808\n",
      "step 1300: train loss 2.0243, val loss 2.0631\n",
      "step 1400: train loss 1.9928, val loss 2.0369\n",
      "step 1500: train loss 1.9699, val loss 2.0306\n",
      "step 1600: train loss 1.9627, val loss 2.0476\n",
      "step 1700: train loss 1.9412, val loss 2.0150\n",
      "step 1800: train loss 1.9098, val loss 1.9967\n",
      "step 1900: train loss 1.9082, val loss 1.9873\n",
      "step 2000: train loss 1.8838, val loss 1.9931\n",
      "step 2100: train loss 1.8734, val loss 1.9754\n",
      "step 2200: train loss 1.8621, val loss 1.9638\n",
      "step 2300: train loss 1.8550, val loss 1.9528\n",
      "step 2400: train loss 1.8423, val loss 1.9425\n",
      "step 2500: train loss 1.8172, val loss 1.9422\n",
      "step 2600: train loss 1.8302, val loss 1.9399\n",
      "step 2700: train loss 1.8168, val loss 1.9368\n",
      "step 2800: train loss 1.8013, val loss 1.9212\n",
      "step 2900: train loss 1.8052, val loss 1.9309\n",
      "step 3000: train loss 1.7970, val loss 1.9192\n",
      "step 3100: train loss 1.7700, val loss 1.9176\n",
      "step 3200: train loss 1.7499, val loss 1.9045\n",
      "step 3300: train loss 1.7564, val loss 1.9046\n",
      "step 3400: train loss 1.7589, val loss 1.8987\n",
      "step 3500: train loss 1.7387, val loss 1.8945\n",
      "step 3600: train loss 1.7267, val loss 1.8880\n",
      "step 3700: train loss 1.7284, val loss 1.8812\n",
      "step 3800: train loss 1.7209, val loss 1.8883\n",
      "step 3900: train loss 1.7241, val loss 1.8776\n",
      "step 4000: train loss 1.7136, val loss 1.8592\n",
      "step 4100: train loss 1.7108, val loss 1.8684\n",
      "step 4200: train loss 1.7077, val loss 1.8647\n",
      "step 4300: train loss 1.7007, val loss 1.8449\n",
      "step 4400: train loss 1.7053, val loss 1.8586\n",
      "step 4500: train loss 1.6878, val loss 1.8450\n",
      "step 4600: train loss 1.6867, val loss 1.8314\n",
      "step 4700: train loss 1.6836, val loss 1.8416\n",
      "step 4800: train loss 1.6687, val loss 1.8445\n",
      "step 4900: train loss 1.6717, val loss 1.8331\n",
      "step 4999: train loss 1.6647, val loss 1.8235\n",
      "\n",
      "And they bride with that yet King thou was to take Ourtuned?\n",
      "It us bartht he usque, to bardetle\n",
      "Hate away, my fears' comzorm he owns,\n",
      "Hof is heart milending, and if ensent,\n",
      "A latistriviov the does me now on you so, like die; litthus wonchiry:\n",
      "Auf the speak you love's nor\n",
      "To this deserving would that\n",
      "To Winsught their as to them, His The shire\n",
      "And Let were to\n",
      "To knom thrugh fir tression must wind.\n",
      "\n",
      "MUKENIUS:\n",
      "Marry, I hom.\n",
      "\n",
      "HENRY BOLINGBROY:\n",
      "\n",
      "Shose Warwick, stavoin cour and teyerry to-chan you!\n",
      "My firders, I mary thou contrantym of a cemmiev-sent,\n",
      "For swittle and whom the head not\n",
      "us body. I much friencess,--cas lord\n",
      "In as dettured themseled Peepent:\n",
      "Is Lady pass\n",
      "Let our graive troye so upon sure fear tall:\n",
      "Whith I sheall night, sir, I do,\n",
      "To may I want beakes againce uncest the leve bunlown'd thos welcont.\n",
      "\n",
      "QUEEN FIY:\n",
      "In unhild.\n",
      "\n",
      "KING HENRY Gentleman?\n",
      "By sevence of time the shopet eyest of Romytan's whom that that saw\n",
      "And liell made that O\n",
      "For fightlly that it\n",
      "In the glette;\n",
      "you wellough, I am with you,\n",
      "For I hursend; gentle up\n",
      "And hid spingditance and to you or love\n",
      "As be ressitions so me worting.\n",
      "\n",
      "GRUMIO:\n",
      "O thus favett now,\n",
      "An but branedy wouldIng my allied.\n",
      "\n",
      "PORINIUS:\n",
      "Love Pennery, blame, to libean thing breamn'd my have eath I die;\n",
      "Save thou for He wherth our hasts.\n",
      "Let, forther of just defevold;\n",
      "Mad there'd hears subs nithily.\n",
      "\n",
      "SBRAKEN:\n",
      "A dongurlate your heavy begut;\n",
      "Good vonby the town, must a belinence.\n",
      "\n",
      "Me I andnam Gom Three:\n",
      "Thy, delet! Here sove you,\n",
      "But won ullishered, smes on.\n",
      "\n",
      "HERMIORTEM:\n",
      "O, say, as If have to kavil scace:\n",
      "Out.\n",
      "\n",
      "PORANNIA:\n",
      "By, farew-rist are gentlecy prevons dead thy path'd that to both may\n",
      "And wound arwill-say I, give affitely,\n",
      "Fhirst more is Prove at take tway,\n",
      "And then-strough longed with that I races of the hamonglings?\n",
      "\n",
      "LADY BOLYCUS:\n",
      "What befair, But I hort.\n",
      "\n",
      "ANGELO:\n",
      "First: life he putilt our side thee, our knong of answeet.\n",
      "\n",
      "MENMARDIUS:\n",
      "You nseat, Joar at Vence stan, Jurion patient:\n",
      "In is shown's fortunds, such I he have wongra\n",
      "Marr\n"
     ]
    }
   ],
   "source": [
    "nano_GPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399264dc",
   "metadata": {},
   "source": [
    "During the process of fine-tuning the nanoGPT model, we made adjustments to various hyperparameters in order to enhance the quality of the generated samples. Initially, we used a batch size of 16 and a block size of 32, along with other specific settings for the learning rate, embedding size, number of attention heads, and layers.\n",
    "\n",
    "After training the model with these hyperparameters, we observed that the loss values gradually decreased over the course of training, reaching a final value of 1.6647 for the training loss and 1.8235 for the validation loss at step 4999. The entire training process took approximately 6 minutes and 11 seconds, which was quite reasonable.\n",
    "\n",
    "However, despite these improvements, the generated samples still lacked coherence and contained nonsensical phrases. Here's an example of the output:\n",
    "\n",
    "> \"And they bride with that yet King thou was to take Ourtuned? It us bartht he usque, to bardetle Hate away, my fears' comzorm he owns, Hof is heart milending, and if ensent, A latistriviov the does me now on you so, like die; litthus wonchiry: Auf the speak you love's nor To this deserving would that To Winsught their as to them, His The shire And Let were to To knom thrugh fir tression must wind.\"\n",
    "\n",
    "These generated samples indicate that further adjustments are needed to improve the coherence and naturalness of the generated text. While the initial hyperparameter settings showed some progress, it's evident that additional fine-tuning or modifications may be necessary to achieve more human-like outputs.\n",
    "\n",
    "I've read some Shakespeare but I'm not sure what language this model's speaking at the moment. Makes me wonder whether or not you can use suboptimal models to come up with fictional languages in fantasy stories or something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092d908",
   "metadata": {},
   "source": [
    "### Step 2: Finetuning itself\n",
    "Let's see in what ways playing with the parameters canst enhance thy model's performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e2e96",
   "metadata": {},
   "source": [
    "#### First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1d856e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T14:54:00.152138Z",
     "start_time": "2023-06-11T14:36:56.670661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215873 M parameters\n",
      "step 0: train loss 4.3519, val loss 4.3466\n",
      "step 200: train loss 2.3973, val loss 2.4120\n",
      "step 400: train loss 2.1847, val loss 2.2275\n",
      "step 600: train loss 2.0205, val loss 2.0845\n",
      "step 800: train loss 1.8880, val loss 1.9965\n",
      "step 1000: train loss 1.8060, val loss 1.9360\n",
      "step 1200: train loss 1.7500, val loss 1.8981\n",
      "step 1400: train loss 1.7169, val loss 1.8683\n",
      "step 1600: train loss 1.6902, val loss 1.8416\n",
      "step 1800: train loss 1.6586, val loss 1.8097\n",
      "step 2000: train loss 1.6395, val loss 1.8056\n",
      "step 2200: train loss 1.6261, val loss 1.7886\n",
      "step 2400: train loss 1.6072, val loss 1.7776\n",
      "step 2600: train loss 1.5970, val loss 1.7691\n",
      "step 2800: train loss 1.5871, val loss 1.7552\n",
      "step 3000: train loss 1.5761, val loss 1.7457\n",
      "step 3200: train loss 1.5639, val loss 1.7444\n",
      "step 3400: train loss 1.5580, val loss 1.7523\n",
      "step 3600: train loss 1.5515, val loss 1.7245\n",
      "step 3800: train loss 1.5452, val loss 1.7272\n",
      "step 4000: train loss 1.5351, val loss 1.7184\n",
      "step 4200: train loss 1.5308, val loss 1.7123\n",
      "step 4400: train loss 1.5255, val loss 1.7047\n",
      "step 4600: train loss 1.5209, val loss 1.7037\n",
      "step 4800: train loss 1.5128, val loss 1.7002\n",
      "step 5000: train loss 1.5104, val loss 1.6915\n",
      "step 5200: train loss 1.5039, val loss 1.6896\n",
      "step 5400: train loss 1.5034, val loss 1.6914\n",
      "step 5600: train loss 1.4982, val loss 1.6827\n",
      "step 5800: train loss 1.4944, val loss 1.6763\n",
      "step 6000: train loss 1.4909, val loss 1.6761\n",
      "step 6200: train loss 1.4868, val loss 1.6718\n",
      "step 6400: train loss 1.4853, val loss 1.6726\n",
      "step 6600: train loss 1.4857, val loss 1.6652\n",
      "step 6800: train loss 1.4815, val loss 1.6614\n",
      "step 7000: train loss 1.4799, val loss 1.6694\n",
      "step 7200: train loss 1.4779, val loss 1.6670\n",
      "step 7400: train loss 1.4715, val loss 1.6615\n",
      "step 7600: train loss 1.4638, val loss 1.6434\n",
      "step 7800: train loss 1.4629, val loss 1.6503\n",
      "step 8000: train loss 1.4665, val loss 1.6496\n",
      "step 8200: train loss 1.4633, val loss 1.6407\n",
      "step 8400: train loss 1.4604, val loss 1.6407\n",
      "step 8600: train loss 1.4666, val loss 1.6418\n",
      "step 8800: train loss 1.4565, val loss 1.6384\n",
      "step 9000: train loss 1.4547, val loss 1.6425\n",
      "step 9200: train loss 1.4536, val loss 1.6494\n",
      "step 9400: train loss 1.4580, val loss 1.6417\n",
      "step 9600: train loss 1.4507, val loss 1.6378\n",
      "step 9800: train loss 1.4526, val loss 1.6471\n",
      "step 9999: train loss 1.4519, val loss 1.6375\n",
      "\n",
      "The glarrify, my dead, how eatily these,\n",
      "I'll the dreig at shall you friend an I\n",
      "Richards in a petty minestion; to five that prish; I she;\n",
      "She's ronoud own- Aument win where the to brother a would spest\n",
      "Desence.\n",
      "\n",
      "PETER:\n",
      "A beat is she chrince baland hate ever eighed?\n",
      "\n",
      "COMINGS:\n",
      "Sinc not, it he not day, like know sonsel's cloud!\n",
      "Had my brink? sing of un facke, ill do-beare.\n",
      "\n",
      "PETAS:\n",
      "Fear somes not fear; more's himour's no were helse\n",
      "Of rembend but he kingly nail! I mu us you fie\n",
      "Ay, he standium at against and no can serve aitor,\n",
      "As his words wherein are husbe and he own but\n",
      "That, genentleman: when, God at the hight svern'st\n",
      "I servies on; he'sew and redd thy than glife.\n",
      "\n",
      "KING HENRY VI:\n",
      "My tY Lord in where, from for he in Chan's\n",
      "The fance, musinad hear i' hearting to his good,\n",
      "The pedients offence can abore the keep\n",
      "That a mers ere brother creen\n",
      "They may! Was you that wilt to ere unturnent,\n",
      "Which I heer is abring oppose. Comis, here\n",
      "down he with the tarres, to-heard or my qreasurent of his\n",
      "brother leave defen and hath accesle that censible hit,\n",
      "That shows: them the is was feea, lew their sotlors\n",
      "Merrow much unloy.'\n",
      "\n",
      "CORIOLANUS:\n",
      "Forbunt I, what speaks gentlement, fain, title me.\n",
      "\n",
      "MENENIUS:\n",
      "I Peace?\n",
      "\n",
      "COMINIO:\n",
      "The look the will this for my life\n",
      "Art the of brotHer hoart. But hither you\n",
      "befood the seast of the atting reworn's nay,\n",
      "You was knoble in etters agare his acquection\n",
      "Rould prove good or unmannered agains, I haved gentle;\n",
      "I, well the good smally abose ur from the fresemnants\n",
      "Stringolding hencledne ten his dise and lesisped?\n",
      "\n",
      "WARWICK:\n",
      "Glow to was O name-tiger nature Suppet sent full\n",
      "Came; I proclent that be heir? Now he hand, you mine.\n",
      "I cuty, some to be night.\n",
      "What, one Rome! he againt that he streal I say of mine\n",
      "I may gracive kinds, and and being to be viorts!-\n",
      "MoRCuss?\n",
      "\n",
      "GEORIOL:\n",
      "Well thou know thy due who you, letth aid and\n",
      "Their easured Fromment, it the spch's he filts, one\n",
      "I may my resourt mycome for you;\n",
      "Here say wheve the earts, we'll so go that sweat\n",
      "Friend one\n"
     ]
    }
   ],
   "source": [
    "nano_GPT(batch_size=32, block_size=128, max_iters=10000, eval_interval=200,\n",
    "learning_rate=5e-3, eval_iters=400, n_embd=64, n_head=8,\n",
    "n_layer=4, dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb112ca6",
   "metadata": {},
   "source": [
    "In this scenario, the batch size is increased to 32, the block size is increased to 128, and the number of heads is increased to 8. Additionally, the number of layers remains at 4, and dropout with a rate of 0.2 is added.\n",
    "\n",
    "The last iteration presented this `step 9999: train loss 1.4519, val loss 1.6375`. Better numbers however on the generated text....\n",
    "\n",
    "I honestly don't know what I'm reading. Live long and prosper. Valar morghulis. To the model's credit it is generating content that <i>resemble</i> conversations and words, but is still struggling. What was generated seems more like if someone completely unfamiliar with English suddenly tried to \"draw\" English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87a9fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T17:26:05.145768Z",
     "start_time": "2023-06-11T14:54:00.159095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.423233 M parameters\n",
      "step 0: train loss 4.3897, val loss 4.3945\n",
      "step 1000: train loss 1.6204, val loss 1.7797\n",
      "step 2000: train loss 1.4688, val loss 1.6519\n",
      "step 3000: train loss 1.4147, val loss 1.6089\n",
      "step 4000: train loss 1.3782, val loss 1.5806\n",
      "step 5000: train loss 1.3555, val loss 1.5709\n",
      "step 6000: train loss 1.3381, val loss 1.5585\n",
      "step 7000: train loss 1.3257, val loss 1.5542\n",
      "step 8000: train loss 1.3148, val loss 1.5490\n",
      "step 9000: train loss 1.3042, val loss 1.5387\n",
      "step 10000: train loss 1.2998, val loss 1.5452\n",
      "step 11000: train loss 1.2906, val loss 1.5247\n",
      "step 12000: train loss 1.2832, val loss 1.5256\n",
      "step 13000: train loss 1.2785, val loss 1.5201\n",
      "step 14000: train loss 1.2716, val loss 1.5225\n",
      "step 15000: train loss 1.2717, val loss 1.5183\n",
      "step 16000: train loss 1.2649, val loss 1.5050\n",
      "step 17000: train loss 1.2619, val loss 1.5021\n",
      "step 18000: train loss 1.2634, val loss 1.5116\n",
      "step 19000: train loss 1.2573, val loss 1.5001\n",
      "step 19999: train loss 1.2534, val loss 1.5092\n",
      "\n",
      "KING EDWARD IV:\n",
      "Arise my good lord? what voasit march the heaver?\n",
      "\n",
      "GLOUCESTER:\n",
      "Ster, Lewishton him see anot, what is London sun,\n",
      "Quing as a citain time, to Senaliny,\n",
      "I had not fair thought it; but I do mutite touch,\n",
      "And, that is he a long sweish threaven may false in to\n",
      "come, one him, or a princely the here in these.\n",
      "\n",
      "QUEEN ELBARD\n",
      "The earthle and all turn Parde for Humbliace.\n",
      "3 KING HEry Vilera delivers upon my subjest;\n",
      "And, no more swiftort for your wises, for with it\n",
      "I amiditie standly her every our dates;\n",
      "And art may take a deprect of thence umhane.\n",
      "Madam, sit of my heart upon the horsel ean.\n",
      "\n",
      "UKE VINCENCE:\n",
      "I call her soldier commends!\n",
      "O nor imallo, thou hopess, hast been madain\n",
      "Before I move tribund to stand this mine kind\n",
      "Of thy aske to extrumesty repretite,\n",
      "So let palace that I presast. Give me men'd blemight.\n",
      "\n",
      "This:\n",
      "Hyow are seed the comensce.' Come, of the whot!\n",
      "Once citizen this surp, marre to me, heare Death,\n",
      "When accepts hold the more from dreams the fools\n",
      "Leish sees it to, as it of mine own of Encepture:\n",
      "Do foes, sit, my lord, to be many hit more,\n",
      "Than the wold I wise pitch followers. Lo, for my Lord;\n",
      "From my life: I do, it love my learness,\n",
      "We foe to for possible he of Rome frome morgetine;\n",
      "Both love on he had before drives, one of the gate\n",
      "Do him harthy relvering foref by the too\n",
      "An eyet to be you, thou slay yound thine field;\n",
      "It seery of Lord fresh marries leavin to this\n",
      "Befixt him a mockarged valintainate.\n",
      "\n",
      "LADY ANNE:\n",
      "O marchance the Ployal will come hips of mear,\n",
      "To betide not the house of Ladyel, but of in hours,\n",
      "And lords hath splaced me to angry Angelo,\n",
      "And conceaerly writh her devil; forsight this be\n",
      "That I am play me bing to have beding an,\n",
      "And I say this prophets it the cars,\n",
      "I bear a happpokinted very drom to for true,\n",
      "I would, hie will. Shame too her, madam!\n",
      "But you be not betake, camedion.\n",
      "\n",
      "VAUG HORCARD:\n",
      "Whenher, madam, is't for the day rudge of a\n",
      "stanspaster? The execution for seem's hand acciden\n",
      "Your stame, of the procunting of appearle's\n"
     ]
    }
   ],
   "source": [
    "nano_GPT(batch_size=64, block_size=256, max_iters=20000, eval_interval=1000,\n",
    "learning_rate=5e-3, eval_iters=2000, n_embd=64, n_head=16,\n",
    "n_layer=8, dropout=0.2)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5gAAALHCAIAAABkBXp8AAAgAElEQVR4nOzdP0/j2rf4fx9+p7+PwApXIKhM7hOIIl0KJMR0JnWUhoYpEJ1JcYsoHZoCGpqQOko3I6Qppgh+BJGlrwQCieCH8ZEyv8Ln+OTkj7Ntb3tv2+9XcTRnJjibxElWltde64/fv38bAAAAQNHsqF4AAAAAkASBLAAAAAqJQBYAAACFRCALAACAQiKQBQAAQCERyAIA5PN933Vd3/dVLwRAmf2pegEAgLIZDoedTif4s2VZh4eHp6en7XZb7aoAlM8f9JEFAEjkum6z2Vz7T5ZlXV1dHR8fm6aZ86oAlBKBLABAmogodpFlWV++fDk5OWk0GjmsCkBZEcgCAOTwfb9Wq8X9Kdu2T09PSdMCSIBAFgAgge/7Z2dnnuclPgJpWgBxEcgCACSo1+tpotglpGkBiCCQBQCk1Wq1xuNxFkcmTQsgAoEsACCVbrfb7/dzuCPStACWEMgCAJJbbBmbG9K0AAIEsgCAhASbbWUqSNMybQGoJgJZAEASyZptZSdI015cXFB4AFQHgSwAIAm5bQrksm3769evFB4ApbejegEAgOLpdrvaRrGGYYzH42azubOzU6/Xh8Oh7/uqVwQgE2RkAQDxKNnglZJlWYeHh6RpgZIhkAUAxKDDBq+ULMu6urqijRdQAgSyAIAYdC6NjYs2XkDREcgCAERlN8FLOaYtAEVEIAsAEJLbBC+1SNMCBUIgCwDYrgSlsQmQpgU0RyALANiuTKWxCbA/DNATgSwAYIsSl8bGReEBoBUCWQBAlCJ2jc0H88MA5QhkAQAb+b5fq9VUr0J3lNICqhDIAgA2oqggFgoPgJwRyAIA1qOoIDEiWiAfBLIAgDUoKpCFUlogOwSyAIA1Kt5vKwtBKW273Va9EKA8CGQBAMsoKsgUm8MAWQhkAQD/QlFBbpizAKREIAsA+Bc6FeQv2Bx2cXFBRAvEQiALAPgHRQVqEdECsRDIAgD+sbOzo3oJMAwiWkAMgSwA4C8UFWiIOlogAoEsAMAwDMN13WazqXoV2IheB8AqAlkAgGHQOLY46EcLhAhkAQDs8SokZoYBBLIAUHU0ji06x3FOTk6IaFFBBLIAUHXs8SoHGh2ggghkAaDSSMeWD0W0qA4CWQCoNPZ4lRhFtCg9AlkAqC72eFUBJQcoMQJZAKgu0rGVQskByodAFgAqqtvt9vt91auAAo7jkKBFORDIAkAVsccLwfBbErQotB3VCwAAKHB9fa16CVDM87xOp7Ozs9Ptdn3fV70cIAkysgBQOaRjsYoWBygiAlkAqBwmIGCToMVBr9dTvRBACIEsAFSL67rNZlP1KqA7ErQoBAJZAKgWWm5BHBvCoDkCWQCoECYgIAHqDaAtAlkAqBDSsUiDBrTQDe23AKAqhsMhUSzS6Pf7tVqt1Wq5rqt6LYBhkJEFgOrY2SF5AWksy7q/v2c3GNTiTQ0AKmE4HKpeAkrF87xms1mv1zm1oBAZWQCoBNKxyA7NDaAK72sAUH7dblf1ElBm4bRbsrPIGRlZACg/0rHIk+M49OpCPnhrA4CSIx2LnPX7/Z2dHU485ICMLACUHOlYKER2Fpni3Q0AyoysGNQKsrPUziIjZGQBoLR836/VaqpXAfxlMBjQ2QBykZEFgNJ6eHhQvQTgH51Oh76zkIuMLACUFtWx0BNTwSAL73EAUE5Ux0JbwVSwVqvluq7qtaDYyMgCQDmRjkUh2LZ9e3trmqbqhaCQeJsDgBIiHYuiGI/HtVqNMxbJkJEFgBIiHYsioq0B4uKdDgDKhuQWCipoa0DhLMSRkQWAsiEdi6KzbXs0GqleBQqANzsAKBWadKIExuMx88AggowsAJRKvV73PE/1KgA56DiLaGRkAaA8hsMhUSzKJOg4S9k3NiEjCwDlQToWZUVqFmsRyAJASbiu22w2Va8CyBCbwLCEQBYASoJ0LCqCdrMIUSMLAGXgui5RLCqi0+m0Wi3Vq4AWyMgCQBmQjkUFkZoFGVkAKDzSsagmUrMgkAWAwru7u1O9BECNYHQCU20ri0AWAIrN9/3xeKx6FYBK9JqtLAJZACi2h4cH1UsA1Ov3+/V63fd91QtBrtjsBQDFtrNDSgL4BzvAKoW3PwAoMC6nAkvYAVYpZGQBoMBIxwJrMdK2IngHBICiGg6HqpcAaMrzvGazyWuk9MjIAkBRMQQB2Mq27dFopHoVyAoZWQAoJIYgACLG4zHdDEqMjCwAFBLpWCCWyWRCyWz5kJEFgOIhHQvERclsKRHIAkDxMJMWSKDT6dCxrmQoLQCAgvF9v1arqV4FUFSWZU2nU9WrgBxkZAGgYJhJC6TheR7bv0qDjCwAFAxDEAAp2P5VArwbAkCRsFsFkIXtXyVARhYAioR0LCDXYDBot9uqV4GEeEMEgMIgewRIRyuDQiMjCwCFwRAEICNMsi0oMrIAUAwMQQCyMx6PW62W6lUgNgJZACgGhiAAmSKWLSJKCwCgABiCAOSDcQnFQkYWAArg+vpa9RKASgjGJaheBUSRkQUA3ZGOBXJGXrYoyMgCgO6YSQvkjLxsUZCRBQDdMQQBUIK8rP54cwQArTEEAVDF8zz6GGiOjCwAaI0hCIBazErQGRlZANAXQxAA5egvqzMCWQDQ1+XlpeolADDG43G321W9CqxBaQEAaMp13WazqXoVAP4yGAza7bbqVeBfyMgCgKaYSQtopdPpsPlSN2RkAUBHDEEA9DSfz1UvAf8gIwsAOmIIAqAhy7JULwH/QkYWAHTEEARAQ7PZzDRN1avAP3ijBADtsD8a0NBgMCCK1Q2BLABo5/v376qXAOBfHMehZYGGCGQBQC/D4ZAhCIBWHMfp9XqqV4E1qJEFAL0wkxbQCiNqdUYgCwAaYQgCoBXLsqbTqepVYCNKCwBAIwxBALTy48cP1UtAFAJZANCF67rj8Vj1KgD8ZTKZ0KZAcwSyAKAL0rGAPgaDQaPRUL0KbEGNLABogZm0gD7Y4FUUZGQBQAvMpAU0YVkWUWxRkJEFAPVIxwL6mM/nqpcAUWRkAUA90rGAJiaTieolIAYysgCg3s4OaQVAvcFgwBzaYuGtEwAUGw6HqpcAwHAchyi2cMjIAoBipGMB5ZjgVVC8ewKASqRjAR0wwaugCGQBQKVv376pXgJQdUzwKi4CWQBQZjgcep6nehVApTmOwwSv4qJGFgCUqdfrBLKAQkzwKjoCWQBQw3XdZrOpehVApTH7oOgoLQAANS4vL1UvAag0Zh+UAIEsACjgui5FBYBClMaWA6UFAKAA1bGAQpTGlgaBLADkjepYQK3ZbEa/rXKgtAAA8kZ1LKAQXWPLhEAWAHJFdSygEKWxJUNpAaBet9sN/vD6+npwcBD81zCM/f19wzD29vYMw9jd3TUMgyxCCVAdC6hiWdZ0OlW9CshEIAso5vt+rVaL9SOWZR0eHh4cHISR7u7uLjFuIVAdCyhEaWz5EMgC6u3syCnyWQxwiW71RDoWUGUwGLTbbdWrgGQEsoB6mQY3lmV9+fKF0FYHpGMBVei3VVYEsoB6rVZrPB7nc19h1vbk5IQdDzkjHQuowijasvpT9QIAGMHWrnx4nhfEUv1+31jI1x4fH5OszRTNCgBVGEVbYgSygHrBni0lwrjW+DtZe3p6SlCbBXrHAkrQb6vcKC0A1EvQuCBrBLVyDYfDTqejehVA5dBvq/QIZAEtyGpckIUgqP369St7xRKjOhZQYjKZkI4tN30/O4FKsW1b9RI28jxvPB43m81arVav17vdru/7qhdVJMPhkCgWyB9FBVVARhbQQuEuPQe7xGh9IIJ0LJA/igoqgkAW0IKGZbLibNs+PT2l0/ha3W43aBABIE8M8aoIAllAFyXI21mWdXV1xf6wRTpXPwNlxRCv6uAdFtDF1dWV6iWk5Xlep9MJSmmHwyGltN1uV/USgMqxbZsotjrIyAIaKV/2rso52kKXiwDFRVFBpZTtUxMoNJ17FyRT5Rzt9fW16iUAlTMYDIhiK4WMLKCRKuTwKrIzzHXdZrOpehVAtdi2PRqNVK8CuSKQBfTSarXG47HqVeTBtu2vX7+WtXtXCbbuAYVDUUEFUVoA6OXr16+ql5CTYMhCKScsMAEByB9FBdVERhbQTnWSsouCbWHlKDkgHQvkjKKCyiKQBbRThUrZCEUvOWACApA/igoqi0AW0BHBUDAC9+LiolgfThX/EgIowfiDKiOQBTTF5elAsTrRVrMsBFDIsqzpdKp6FVCGQBbQFLm9JfqXHNByC8gfRQUVR9cCQFOmaQ4GA9Wr0EjQ5WBnZ6fb7bquq3o5a1xeXqpeAlAtjuMQxVYcGVlAa1yq3kS3ItrhcNjpdFSvAqgQigpgEMgC+qNYNpomEe3ODhe4gFxNJhOda42QD955Ad39+PFD9RK05nlev9+v1Wr1en04HCqZrdBqtfK/U6DKHMchioVBRhYoBDZ+xWLb9unpaW7teNjjBeSMogKECGSBYiCWTSCfiJbaDyBnFBUgRGkBUAymaU4mE9WrKJjxeNzpdHZ2dlqtVkaNDrrdLlEskCfbtoliESIjCxSJ7/tnZ2dETonJbUZLmhzI33w+V70EaISMLFAkpmlOp1PLslQvpKjCZrRBjjblzrCzszNZCwMggu7aWEJGFiikbrfb7/dVr6IMLMs6PDz8+vXr7u5urAZePAVAztjjhVUEskBRsVleuqAl7cnJydbaA8YfAPljGi1WEcgCxcbor4wEHQ+Oj49XPzgpjQXy5zhOr9dTvQpoh0AWKDyyg5kK0rT7+/tBUMt+OyB/FBVgEwJZoCQo2cyBZVmEsED+aByLTQhkgfLwff/6+ppKAwBlYtv2aDRSvQpoikAWKBvXdS8vL0kcAigHGsciAn1kgbJpNBrT6XQymdBuFkDR0TgW0cjIAmXmuu7d3R3FBgCKiD1e2IpAFig/3/cfHh7YCgagWGgci60oLQDKzzTNXq83n88HgwH1BgAKwXEcolhsRUYWqJwgQfv9+3c2hAHQFnu8IIJAFqgu13V//vxJRAtAN4PBoN1uq14FCoBAFgA5WgAaoXEsxBHIAviH7/u/fv16enqi0QEAVdjjBXEEsgDWo/AAQP4cx+n1eqpXgcIgkAWwHUEtgBzQOBZxEcgCiMd13ff3d8oPAEg3mUwajYbqVaBICGQBJBfW1L68vJCsBZAGe7yQAIEsAGnCZC1xLYC42OOFBAhkAWTC9/2Pj4+fP3++vr5ShAAgGnu8kAyBLIA8BEUIb29v7BgDsIQ9XkiMQBaAAhTXAgixxwuJEcgCUCwsQiBZC1QQe7yQBoEsAL3Q3guoFPZ4IQ0CWQD6YmQuUG7s8UJKBLIAioHpYkDJsMcL6RHIAigY0rRAObDHC+kRyAIoMNd17+7uiGiBwmGPF6QgkAVQBkS0QLGwxwtS7KheAABI0Gg0RqPRfD4fDAaWZaleDoAog8GAKBZSkJEFUEK+7z88PPT7fdULAbCMPV6QiEAWQJkNh8Nv377R6ADQB3u8IBGBLIDy833/+vqaClpAOfZ4QS4CWQBVQb0BoBx7vCAXm70AVIVpmr1ebzabOY6jei1AFbHHC9KRkQVQRWRngZyxxwtZIJAFUFG+79dqNdWrAKqCPV7IAqUFAKqo2+0SxQK5sW2bKBZZICMLoFpoyAXkbz6fq14CyulP1QsAgJy4rnt5eUkIC+RsMBioXgJKi4wsgPKjjyygCnu8kCkysgDKjO4EgFr39/eql4AyI5AFUFrdbpcQFlDIcRz2eCFTlBYAKCF2dAE6YI8XskZGFkCpsKML0AR7vJADMrIASoIdXYA+2OOFfBDIAigDymEBrcxmM9M0Va8C5UdpAYBioxwW0I3jOESxyAcZWQBFRS0BoCf2eCE3O6oXAABJdLvdWq1GFAvohj1eyBMZWQAFQy0BoC3btkejkepVoEIIZAEUBrUEgObY44WcUVoAoBioJQA0xx4v5I+MLADdMeMA0B+NY6EE7bcAaC2HBrGWZR0eHhqGcXBwsL+/bxjG3t5e8E+7u7uCB/n4+Njd3f34+Hh/fzcM4+3t7fX11TCMl5cXQnBUwf39veoloIrIyALQVEaJ2CBsPT093dvb293dze1KqO/7Hx8fP3/+fH19JbpFybDHC6oQyALQkdxErG3bQeTaaDRkHTM9QluUBo1joQqBLAC9+L5/dnaWPqoLgtfj4+Oi7D5ZjGvZ04YCGQwG7XZb9SpQUQSyADQyHA47nU6aI9i2/fXrV60yr8n4vv/r16+npyeStdAZe7ygFoEsAF20Wq3EmcjSxK9rhUEtmVrohsaxUItAFoB6rus2m80EP2hZ1tXVVaUua7qu+/Pnz+/fv5OmhXKO4/R6PdWrQKURyAJQLNm+rnKnYEWQpoVaFBVABwSyAFRKUE7gOM7FxQVXMxe5rnt3d0dEizxNJpMqf5OEJghkAaiRoDsB1zG3CgoPsh4hAfBihCYIZAEoELcolk/NuMjRIlM0joUmdlQvAEDldLtd8SjWtu3ZbEYUG1ej0RiNRvP5fDKZ2LatejkolcFgoHoJwF/IyALIlXhRrGVZ9/f3FOHJMhwOv337Rq8DpMQ0WmiFQBZAfsSjWGYFZSTodUBEi8RoHAutEMgCyEm9XhcJnsj35INtYUiAb5jQDYEsgMyJNyjgYzJ/bAuDIBrHQkMEsgCy5ft+rVbbejPLsn78+MElS1UoOcBWFBVAQ3QtAJAhwSjWcZzpdMpnpEKmabbb7el0OpvNHMdRvRxoZzAY8AqFhsjIAsiKYBRLOYGeKDlAiKICaItAFkAmBKNYLlZqjpIDGLxOoTFKCwDIJxLFWpbFp6P+KDmA4zi8TqEtAlkAkgU9CqJvY9s2RbFZa7VaOzs7rutKOZppmr1ej1FhVWNZFnP1oDNKCwDIJNJpi06xOeh2u2GPWNu2b29v5X5t8H3/4eHh+/fvlByUG5dNoDkCWQAybZ16QBSbg+Fw2Ol0lv4yo0117AkrMcdxSMdCcwSyAKTZOoGWKDYHa6PYQKaP/3A4ZE9YmdCpAIVAIAtADqJYHUREsQHLsu7v7xuNRkYLYPJtaVBUgEIgkAUgwWJF5lpkd3KwNYoN5dC7lwRtodHdGUVBIAsgLdd1m81mxA2IYnOw9bvEkslkkl1eNhTsCSNBWyy8YFEgtN8CkIrv+9FRrGEYP378yGcxldVqteIGi+/v7xktZlHYtGswGFiWlcM9Ij1esCgQAlkAqWxtGTuZTKi0y47ruvV6Xf+mAUxVKIrBYMALFgVCIAsguVarFV0EORgMcrh+XU2+77darWazWaA6VBK0mrNtm9JYFAs1sgAS2rq1KHGbAt/3yQlFkFJ4mk+NbDTf96+vr/VPJ1fHfD5XvQQgHgJZAEn4vl+r1SJukHi/SBAfB+m6w8NDwzAODg729/f39vZ2d3cNw6hyjCtx75RWIQstDjSRdXc2QDoCWQBJbO0amzjht7UHgmEYYZgbxriGYezu7pY4xh0Oh09PT7KSl3puS2dImCYsy7q6uqLGAIVAIAsgtq1FBWkmW27N9UazLGsxwC16Ejej2E7z0aPdbvf79+8kaNUinEUhEMgCiCe7ooLQzo7kfajFyuC6rvv+/i4x/7qqEEObSNDqgHAWmiOQBRBPvV6PTpWlD5KkB7IRggyusVCJa+Qe4waR69vbWz5pSD3rCjZhpIImNM/io7IIZAHEkGlRQWhrrJybpT1nhmHs7+8H/xSEvIGggCHCx8eH8fcMgre3N8MwXl9fX15elPyaOvQrSIANYTqwbfvr169FPH9QVgSyAGKIzpXKSvVt3UmGxBL3RNME9QY6IJyFPhiIAEBUq9WKvsH9/X0+K0FihY5iDcNoNBqj0YgJYWqNx+Nms1mv17vdru/7qpeDSiOQBSDEdd3oNJht22RoNDcYDFQvQQ4mhOnA87x+v1+r1Vqtluu6qpeDiiKQBSDk7u4u+ga3t7ey7iuoRoVcpZw+2m63p9PpZDKxbVv1WqorTNAOh0MStMgZgSyA7UTSsRK3+YcbqiCLZVlFLyqIQL2BDjzP63Q6JGiRMzZ7Adguh5Zbi7b2RkBchWgcKwvzFHRgWdaXL18uLi6qc+JBCTKyALYYDofRMYHjOHI/qxY7WyG9yWRSqWCi1+tNp1PKZ9VarKAdDoeql4PSIiMLYIuc07GGYbiu22w2JR6wyvTpGjscDt/e3nJuqk+7Ln04jnNycqLJ2YjSIJAFEGXrVf4s+pISyMqiSRTr+/7Z2VnwdWg+nytZAOPBNEHJAeQikAUQJf90rEEgK4k+UWytVgv+rHw6brfbJZzVBFMVIAU1sgA22lodK7dZQWjrxFdEsyxrNptpEiKcnZ2Ffw6G/SpE91l9BE27dnZ2mKqANAhkAWz07du36Bt8/fo1n5VAnGVZP3780OS6bbfbXfwudHp6qnAxobD7LOGsDoI9YcwJQzKUFgBYb+v1/ewuEy9ejEYsWZQsJ7b6PGpS7bCI3WC6sSzr6urq+PhYky9j0NyfqhcAQFNbR3ldXV3ls5L0gsTb4eHhwcHB/v7+3t5eWL2w9sMySAt9fHwYhvH+/v729vb6+vry8qJ5a1LHcXLuCRDt+vp66W80LBppNBqNRoNwVh/BYAWDIlqIISMLYA2RnGim2893dtIWPgWfgkHkJDG14/v+x8fH+/v709OTVqHtYDDQagLt2oy+kpYF4nzfv76+JpzVDREtIlAjC2CNh4eH6BvoP9r+5eXFMAzTNOVeoDRNs9FotNvt0Wg0nU7n8/lkMrFtW2215Ww20yqKNQzj8vJy6W/0L0g1TTMYdav/6V0pbAtDBDKyANbYmhDNutgxfUY2YFnW/f19Prkc13V//vyZc3cnrbZ2hda2H9at8iEa2Vlt0YkWiwhkASzbOgTByP4asaxANhBsH8ktZzkcDr99+5ZD1YFWW7sWrX36dCt+EEE4q7OcX9fQE6UFAJY9PT1F36BwF16D7SPBpUnXdbO+u3y6OzmOo2cU2+121/793t5ezitJj2IDnYWv61arlcPrGnoiIwvgX0S2eeXQRGnrRLE0gkuT+Yx9F0lvJ6BzdnNTNl3znV5bkZ3Vn+M4lBxUDRlZAP+ydZuXYRhF3z7seV6/3w+2j7RareFwmN0Okna7LT2fp3MUuykdWwJBdjbY26d6LVgvnK2Q6YsaWiEjC+BftqZC86nLzDQju4lt26enpxl1Yu92u1L2gWk4U2DRpnRsduMzlKDvbCHQt6sKyMgC+Ifv+1vDR02mjGZhPB53Op1arbazsxMMzHRdV1Zep9frDQaDlAfRPIqNSMceHh7muZKsNRqNIDurf0+xKgv6djH8ttwIZAH8Q6Su4Pj4OIeVKBeWH4RT4NPvJmm3247jJP7xwWCgcxRrGEbOrceUazQaOezqQ0rBazksOVC9HEhGIAvgH9+/f4++gWVZFdxIsVhTmzK70+v1klVY6lwXG4iujj04OMhtJTkLwtnBYEA4q7nF7iUkaEuDQBbAX0TqCr58+ZLPYrS1mN1J9nE4Go3iRjy2bWsexRrVS8cuCXqupcm4IzckaMuEQBbAX379+rX1NicnJzmsxIhTUilxC7llWbZtC86bXYxo41YdXF1dxVqVnv1iF20NCF5fXxMfvEDJs16vN5/PCWcLgQRtOdC1AMBfWq3W1l3YubUCFVmM8XcLhZRjwIL5QEvNClzXvby8jNU5IdbVf/G2DLPZTP9yjmRdJizLSvZTxt9fdQ4ODvb39/f29nSrHqbpbOEwJ6yofgPA79+/f//+Y5vz8/PcFnNzc7N1PX/88cfn56f4jVcdHR09Pz9HLOPx8THuAR8fHyX+gjc3N3Ie0CzFfZQycnR0dH5+fnNz8/z8HJwYyj0/Px8dHal+YBDD0dHRzc2NJucPRBDIAvj9+/fv5+fnrW/xeQZVInFeuJ7Pz88En1iCEefn5+f5+XmsI2+Nj3+LBX9HR0dpH8dc6BmrBXHt1iciB4m/aEEhTU4ebEWNLADDMIyfP39uvU1uBbKCLi4ugj+Yphlr+5RlWbPZTPAaYjDPKVYLWM/zms1m9C7+vb29rceJVUqriuu6+Y+uEOF5XtBGNIf5bdF6vZ706W7IWtiDlg1hmiOQBWAYAo23jHwn0+7v70ffwLbtxcpR8ZjPcZzpdBq36jTBpNl+v99qtTb96/v7e/SPW5ZViHK9u7s71UvYLhx1oSouCcfb0qKrWNgQpj8CWQCGYRhbk2o5fwBvTVh+/fp18X8FY77BYNDr9ZItKUFqdjweR8Sy0QqRjvV9v1j7mcK4pNVqpZ9wEVfQcZaeBkUUtChRctogGoEsAEPkrVmrEaOWZa2mh7fGB5PJJH2Os91ux+qvNB6P19YYPD09bb2j2IvLncgoOD0pvHDc6/VIzRZUeNoQzuqD9lsAjG63u7Wbfc6TpXzfr9Vqm/416Lol/iOWZf348UN6EyuRxy2w+uhF96tyHCdx5jhPKRufibAsK/wStTQebLE37cvLS+JSXVV9l8TPH2iIdl26UL3bDIB6Irvy8+9HE7GYTbuJ124Pz7pr2OPjo8i2/cU1b22zUIjt0hl13Qr6HyVooZV+PYKNLCT6/PxU3vNB+QIKTbzjHjJCIAtgewfZP/74Q6tVbQpxVgPE3FqGiYSzizeOvmUh2ljKDYCCgCDlLy5rGbIeIkEK+3MFLd6en59vbm6IaNMoRMvnUiKQBapOpAmrkoamER+rET+1GBPkH5FEN8APH8boFHgh2seKNB4WJLFhZ9yOv5uIdAKWS+LjGdfiMj4/Px8fH2U9jBXEMIX8EcgCEgTv/jc3N+fn58FsofS5pdyIfILmOdMrtOnTdGucF4SSCh//iIRrkLbR8NGOS1asIzdelBsO5p9jUxJBbnoKnp+fz8/PSdMmQHY2TwSyQHLBG33E21khyqdizdDSYWFbA1lNvkJsOje2BiuF+BTceumbSlsAACAASURBVM6IyCL3LD3wyjk1m3+Zwdb3KAoPEijEdZVyoP0WkMRwOKzX681mM7qJZtC0sl6v69xJe3Hr9yZbxxNkIfGdSu9OkMymprPFary6lqyWVVmMBPvy5YvcAzabzcTNgBMImnPldneGQCe4RqPR6/Wm0+lsNnMch8ZhIjzP0/ltv0wIZIF4fN+v1+udTkf8M9jzvFqtpu2b2svLy9bbHB8f57CSJZtmIug5EHWtYB5Y3J9S8rUhlm/fvsk6lPTXRTi4WKLxeJxn69BGozGbzXKLF0XeAQKmaQYR7WQyYazDVh8fH6qXUAkEskA8v379ShZIXV9fS1+MFCK/jpIc5+7u7qZ/0vZbwSrTNBPEsjrzfV/idwnpH/amaQqGgLEGDnue12w21862yIJpmj9+/Mgnlk3wbAY52vl8PplMYj2MlbJ1DDWkIJAF4tl6GW6T8XisYfglsiRVVxIjIpJipTpM04x1sXjreF615E7z+vnzp8SjBQSn+97e3s7n88FgIB6K9fv93MoMTNOcTqf5vPoSvzU1Go3RaDSbzQaDASUHUIJAFognTYHjr1+/JK5EimJFhKG7uzvVS4in0WiU5lLs9+/fJR5NpEQ7LsFhS8Hrsd1uB6GY4BMUlBnk9qU0n1g25fuAaZrtdjssopW1KkAEgSwQQ8pPr7e3N1krkUXk4lc4IDR/mzbuFHG/VK/XE4xIdL4iKbeuwMjsqRRJsi5eXQmqP+fzuUgcFlS951Yy++PHj6zvQlZePHwYKTkwtHzDLyUCWSAGDVOqKYm81S4NuM/TycnJpn/KrVpRIsFL3jqXFsitKwhkkd38+vXr1tus3eTU6/Vms5lIENZsNvOJZXMos5abZTcWSg6q3OVA/12b5UAgC8RQzW/YCt+OI/Z79ft9DWuOowle8tY5Iyse8ViWJXiVOYvvh41GY2v8tKlBkmmao9FIpKy52WzK6kQWLW6ZdVwZdQJZ7HJAghYZIZAFYkhZz6fhF3SR30hhgjB6B7q2jSAiFPrjPFZdged5FxcXazvpLkm8gTKaSP47IoZuNBrz+Xzr89XpdPKJZbMus870a2E1E7Q6X1opEwJZIAbxhotrafi+JvIbRaRFcxDR3348HucTQ0h0enq69TbaJv7j1hU8PDy02+2t4VdGZbIi+e+tMfRoNNq6/txi2V6vl90XoRzqpkjQIhOqR4sBRVK+iYUiK1e7wufn5+jlaTKQVtDn5+fWB1zbEbUJhpQGP/j4+Bh9s4zGwG6dBvyH2Om99ST8Q2DQqxQi508y+Z91n5+f+c/jzVOx3pqKi4wsICrlpTfpkzMrotFoRN/g7Owsn5VIocn43ASS9SsIUpVb87JZdJM1DOP29nbrbUSSqY1GY2uJaj552eyKZaXv99oqbHFQ1h60xX2xFwuBLJCTXq+neglFFR0DeZ6XW4/6fGTRWjW9ZJeew2G2vV4v4nnMKIoSmfIlWKEbjI2Nvk2n08mhj0Gj0cjiurzCyc+l7EFL7URuCGQBUWl6huv5Bq3zWK9FEU24AuPxuGSxrIaSbcla7AwQUeK5qYFAevf399E3EK/QFWmDlU9PrtFolMULU20bkJIlaBV2LawaAlkgD8VNxyqchhASaaU0Ho8L0Vm2cC3DQom3ZC1uEYuIwLLoUGuInTziJQEiV/abzWYOz/LWAD2BjJ6CuIIEbdE3hG39+g1ZCGSBzIl0IFKiQPMdRFop9ft9/fOyInn9lM0xsiCSZbQsa+2p3u/3F/9308zV7Go0t548Yf2DiEajsfUVnUPddhYFBlrVtBS9Y9fW4n5Io3q3GVAYW3der6Vns4Lfv3/L2i98tOD8/Pz8/Pzm5ubx8fH5+fnz81Pivl3B9Zyfn8u6xyyI7KPXsGvB1rPl6OgoeK7X3nJpR/+mrfcZ9S74LXDyxL1rkQcko98llEUHg6zXnNjz87PIa0cT2r7tlxKBLCAqWSCrZweWPD8Swhg3iG4Tr1k88j46OsouJEpD5FfIp4tTXFsbby2e52ufkaUDrm1olV0Ev/WRT/D9Z+tjksN3qmRvShH0fL8KBR27ErSBy5mer+KyIpAFRCX4zNAwtfb8/Kz8Y+Do6Ojm5iZBrBnrXnT7LBGJYvWMv7dm/pYe6rWvlNWnY+0Dkt1vsfXBjxvDiSREczgJ5b6cdXvVbKJ5glbz7wMlQyALiIobyGp4dUnD9uPn5+fi0VuCp0CTTxTxS/Maih4HsPY8X42u1t5sNRbJLpDa+hQk+NopckJm/eVEZFiDOA2/e0fQM0Gr4Tt/uRHIAqLiRlFaZdd0SMRGu7m5EYnkEvwWyj+bt6aOlK8wWnQIuPY8X/tiWXvLpdtkFwSIJFATHFbkhMz6K4rEl3ZBgzCtErRFyWqXBoEsICpWIKtPaPL5+anPW/xWW8tbE+eflHy6fH5+bg0y9P/Yi/gVIuKe1Z9aWzO6+oRmF/Zl8Y1C5ITMOjqUm5TV9sqAiMfHR+Xf2Av9ABYRgSwgKtanherF/kXDWgIR0eFsmrg8zy8YhS4nWBTxK0Q8TWtfL2t/36UHKrvnKKOkrA6dKCR+WdX/m9VWQcmBrAckFs27ppQSgSwgSjyQ1eGTQPp25vxFlM+mTLrEKsxNQORDVJ+cfbSI4G9ronE1utr0Wy89oRn8HhuXlP55EWyDlenbgsRWXEU5M0XkX3KgVUVZRRDIAqLEA1m1aTYdLq5JtPZjVda1VLkRrfinZoE+7SK+EW2NeNY+TWtvuRSHZRfzKUzK/pHxO4OsiK2gZbLR8oloS/nQ6Y9AFhAVK3jKP6uh8GpaDlYjG7kp56Aj2OPjY6xQ4/Pz8/n5+ebmRvwz8vz8vBDlBKGIX03kFxFPyi6evZkGBKoqZbP+vSQmZYt1isby+PiYXUSrw7W4Cvrj9+/fqoeLAcXg+36tVov1I47jXFxcmKaZ0ZICruve3d2Nx+NM70U527ZHo9Hi33S73aXxp7IEIzEPDw8Nwzg4OAj/PpjhGYyQ9Twv7mEHg0G73Za2ylzU6/W1v6llWdPpdOuPr75qIn5w8b6ye6xEXsiz2Szuy3bTA7XEcZxerxfryOJarZaU94EinqhxDYfDp6cniW+bgq8IyKc6kgYKI3HCI7uKzJJVEWy1ujuqKEnowiViQ5t+I/G05epztClxtfgSU5uUTbBlR/wSQXaFJbKSsmUqk90qqDpI/0ZKOlYVAllAVMoPicTjrFZp1TQxf0uPof6xbHE/4SLOefEzefUgEUHq4rOpNuDLdPKcwhZjIqpZ65lyvILq5VcXgSwQQ/pPiMD5+XkQ1Ap+noW1mJXKv0ZYCjK0bdFQ3ERsIOKBjfV7rX7ZiAgTw5NcbVI2wb3HKpXO4pf6LW8fZKHP2/QeHx9jvd8W98tqCVAjC8Sws7OTxWEXKzIXJa7FrILJZNJoNML/dV338vJSn8fKsqz7+/vFFRbRpirkBOWAS6+diCO4rttsNoM/Lz3LEolUysYtFR0Oh51OR/DG2RXLClbrRqtCmawI3/d//fr19vb2/fv3TY8q1bGKqY6kgSIhIaqV1ayeDmUGR0dHpUnPbEoxJshWriZ3RWZeqE3K/hH/enGsUyWjrKeUCxSVKpMVtKlLSYG66ZUSgSwQA4GsblZDgefnZ1VPU5lC2MCmRzJZlLN0tOjL6+HN1FbKxq0BiHXuZRemp38JVLNMNpbPz8/Hx0eiWOUyuU4KAPk4Oztb+ptGozGdTgeDQVCwkQ/LsgaDwXQ6LdnVWLmlGvf394v/Ox6Pfd/fdOPBYBD84fLyUuIaFpmmadt29G3G47HruuLH/PLli/iNPc/rdrvit89oGWt5nhfx7MAwDNM02+120cuHSoBAFkCBeZ7XarVW/77dbk+n08lksjVSScm27clkUr4Q1jCMiDhmf38/wQEbjcbS0/Hw8LDpxu12O/gq4nlerFAyltvb2623iRVJn5ycxFpAv9/P4re7uLhIf5Bfv36lPwiQNQJZIIbV/VhQbjweb0prNRqN0Wg0m82kJ2iDFOxsNhuNRmVNyXx8fEg/5lLg2O/3I8LlMIObaVLWcZzo28TKm+7u7sZdQ7izTSKRZPNWT09PUhYDZIpAFkDhRae1giuA0+l0NptNJhPHcWzbjhvXWpZl27bjOJPJZDabBSnYrGe2lc9q4BiRlA0zuJ7nDYfDjJYk0jogOuBelOyUWHtVIaXT09OURwi6pgCao/0WEIPv+2dnZ/r0eEIoWQecIDpZTD2+v78Hf9jb2zP+TrBVM2CNaCaVsjfTUiuu+Xy+6ZZhk6xMOxyJzDoWX0Cy7ldZtLtK3y4wwaheIG+qd5sBxaNwXzwi0DBIroheZikf6qX+UNGtHsJlZPr8ipxggi0pEr85SO/GlX7KV8m6cKCUyMgCCenWgT89x3H29/cXM5HGhmRkmMh8f39/e3t7fX0dj8d5LnWT7PrnV1Cr1dr0tKZv5r+Yttya7Awzi9klCAVnGYgsIPE8Atu2R6NRgh/cZHG0RDLSlwRIRyALpDIcDr99+1aOcDbiCq8I13Xv7u7URrQZXYD2fT+M2g3DeH19Xb3NwcGBYRj7+/vHx8dGKaoRMg1klwLH6Avr4Y0zjatELsSLLCDNYC3pBQYpqwuYWYUCUJ0SBsrg8fGxBMUGUh6Kz89PteO1ZF0MXTvCR9zR0dH5+Xmh+6VHnNJxxwSstfjYbm2/Hy4mo2lYv4UHYm09wZKdMCG5v2D66oLsHnBACgJZQJpCh7NyB/l8fn6m/wRNLPGyg+BV+pMYBLWFi2gjHgcpZ8vSYK3ox+f5+VniXW8i+NRHx3ZpThXpv2D4uCVGmSw0RyALSFbQrWBScmxLpMx8TyDurqAgfs1nbQWKaKNPYyl3sfiwiydls3sABc/YiBeLyNjbreRua0u5mCzeGQCJCGSBTDw/PytMSSaQ0ZZwVWG9yPXQjPKvIo6OjvRPdEX/CrKuOC8es0BJ2U1PX/oMqMhDEUv6NyJZKwGywEAEIBPhTKmtc4M0kWzo6FaNRuPHjx9yp2qJuL6+3vRPvu8Ph8N6vd5sNvv9vpKNep7ndTqdnZ2d7Pr8Z03W/NLBYBD+OXqCVz7zEcJxYtE2tTj4+fOnlGVIHPeVfjKC4DAIQA3VkTRQCarKZ4+OjgSvm2edIMw/P72aMtQzTa5tdjZ62RKvOC++NKIzkYsX7rPbhCT4Ul37CEh8mct6hNNXO+h5fgIBAlkgP8GO/nwi2sVaTJFANofCzZxD+TAOyPNhTyz4ypH1UxDL1gXLuqPFy/FbDxt+FcmudlO8PGD1KUv27G8iK4JMefJTJgudEcgCCmQaWt3c3Cwlq0QC2Xya7OQcTT4+PmqYgo2gVcSwdbUSz5nFp0k8KZtd6C942iyF3bIKZKU/yOn3MqZfA5ARamQBBUzT7PV60+l0NpsNBoOg8i8l27YHg8F8Pu/1etp24//x40eed9fpdDQZOSZoPB4XqHBWVpmsYRi3t7fhn6MrZU3TDOvOo28paz0RPM/rdrvh/8oqkF10dnaW/iAnJycpj0CZLLRFIAuoZJpmu90ejUbz+TwIah3HsW1bcHeUZVlh/DoajdLMBMon9jVNczKZ5HBHhdbpdFqtlupVbPf09CTrUKZphru+PM9zXTfixhcXF+EtMwr6TdMU/HrZ7/fD1X7//l36SjzPS38ypJ/bLPFLCyAXI2oBfQWTUQ3DeH9/NwwjmI8atBfY29vb3d0VjD673W6/34++Tcr5tLEIzrWvOMuy7u/v04cgiYlMN5V72oTDXbdORl08pTM6dX3fr9VqIrcMV5tyHmyE9KNr0wzONTIeDgykorq2AUDmRCrkcl5SsUpXFVK4YTz/5S3WmEYfebFSNrvCYvGzNChMj/XMxpWyWDblKy7T3r1AGpQWADDy7/MqWIOITqezWIWpA8dxwirVb9++STxy2Cl265EXK2XH43F0KUJi4mdpv9+XUswaIeXxU3aT9TyPMlnoiUAWgAKLNZGI1u/3lZTMbvp6c3Fx0ev1gj9Lj2/C2HFr/Wu4BiOzXV+L4fJWWU/WSFkse3x8nHIBlMlCTwSyANRot9tS2jVUwXg8rtfrOqTELMsKKrPD7yEPDw8Sj78YO25N94a3zG7XV7ixTAfj8Thxej79bk6Je/sAiQhkAShDgYE4z/NqtZryWPbw8DD4Q7vdDlK2W/cRxtXr9YIjLzW3WrUYZXY6nSwenFhJ2Rz0+/3EIXvKCqKXl5c0Pw5khEAWgDK6RQn6yzOWDWPWRQcHB+Gfw67A0rOh9/f3wR+io+Sl8+f6+lruMgJaJWUNw+h0Oslqgr98+ZLmfimThZ4IZAGoFKbfIKhWq2W0t2nJYswaCrq/BcJCZ7lbvox/7/qKTsouVspmtOtLw69bzWYzQUyZfiwCZbLQEIEsAMWurq5UL6FgksUxUuzt7S3+b1BgkEWJalh20u/3o3/ZxSgzo11fuiVljURNDHZ3d1PeadDKGtAKgSxQfotZNA2F1ZYQl0ONwdrTJpjNsSgoMJA+4WIxDxpdM7AYZWa060tJUjYY8rfpXxM0MUi/3yuL0WVASgSyANQLayIhLuvGpUvJ103CAgPpEWRYNhBdM7AUZWY0NC7PpKxlWZPJpNfrra3uCCUopUj5jTHrFmNAAgSyANRrNBokZeNK2Vh0q7VXotdeXA5y6llEkGGTr+iagcVKWcMwsnhYckvKDgaD6XQajCZ+fX2Ve/C1G/hiyac+GxBHIAuUn2BqTS2SsgmMx+PsYtlYV6KDAgPpQ8jCspOtrbgWo8yMdn0thcvS2bY9m83a7bb4j8Qte41O8YpYrS0B1CKQBaDFFcPFjeoQl6ZJ/larafJNVZJBgcHWjVkJLLbiijj40qX/jHZ9ZZeUHQwGo9Eo1peHcDiFuPTl8oxFgG4IZAHogvkIyfT7/Ywu+K5eiY5oJhqMapPezHXxG07EwZcu/We06yuLStkEidhAgr6w6S/OjMfjlEcA5CKQBaALDRt2FkVGDblOT09X/zKimejt7W0Wl/XDbzjRB1+69J9Fza5pmnKvGyRIxIYS9IUNSm9TYiwCtEIgC5SfSCGdJh9OWZchllgWTQyOj49X/zLi4nJQYCD9sv5i+NhsNiNuufRFKIuiC1nXDSzL2pqIjZ4KKyUqTeDj40PJ/QJrEcgC0MtkMlG9hELauh0qgbWZwvF4HPG1p91uHx4eSl/JYvgYcfClS/9Z1OxKSco6jjOdTtM0dk28hvTtQX7+/JnyCIBEf6peAICy8X0/ulDy4ODg9fX19vZ27Qd5o9GYz+e+7//69evp6enl5UWHvWixWJYVVpfmWVPY7/f39/cTVFtGsG179Vd4eHiIyJ3f3t7WarWTkxOJKcOg7KTf7xuG0e/3Nx188WaB6+vr0WgkaxmBr1+/pnlaJ5NJ+kdmbdWHiMPDw5QvKOlNwYBUfgOogD+2eX5+lnVfNzc3W+8u1j1+fn4+Pz/f3NwcHR2JHDl/R0dH5+fnj4+Pn5+fiR8QWdauIbHHx8cE9xI8WRKXEVhcwKbbfH5+Li1V4rkdOj8/T/DUHB0dxXp2Ik74xM9y+rMxi2cWSIxAFqiErR9OEj/sBcPNxJ/Ez8/Pj4+P5+fnyuPaiOB1yefnZ7LQJwG5ccZqXBj+7tE/GAT3Elfy+99BWMTBl2K1LAKv5+fnuM/Lzc1N3HvZdIan+Y02fTOJRe6XJSANAlmgErbGfI+Pj1LuaFPcI/GTeEnOcW0QnyWL+6XEECJkPZuBTQ9s9IMQhHrSs6Eiv+bqSSj3AQnEOt+SLWDT0dJ8Q5ByEmaR5AaSIZAFKiG3QFbwYzK7q5NhHYLE0Da6ciDu8vIJuCXmzDY9p1ufxCAJnWmpw6aDr15Al7iGtcffJG45waJNx0zzak2QS16VILsMZOSP379/qy7TBZC5er0evcNjMBhI2STUarVE9sE4jpNnpy3f9z8+PoLpmm9vb8bChpWgw9Fi5/9gjOf+/v7e3t7u7m6areWbbH060rMsazqdSjmU7/u1Wm3tP9m2HbGVKvhBiSsJ7Oz8028n4uCLNzPkneGG8ElubHt8okU87LPZLPFpGXFYcWl+L0Ay1ZE0gDxsLdCUlWIRzOhkcam3WHIomZWYNotYbfS9BJlLucWyS0nZTQvIKCkrnlBPeZJvqtJJeTVDsPgnGvu9oA/6yAIwDEktdcRHOqUflVl0o9FI7oyoVRK7qH79+jXiXrY2dh2PxxI7yy4lVvv9/tpptKsp/5Rr8H1fPJU+mUxSJoA3zR1YnRsci5QrDIXriIcSI5AFKiG4XJ614Nq9CFVDibQyGo2yHskb3dBXXKPRiGikHxHLhuMDouPduJYet06ns/ZL1NLNFvvLxuX7/tnZmUgAF4zsyu4MT9xBVi5NZgECBLJAJezv70ffIHoYpqCI4aWL0s8WKo1er5dpXnY8Hq/NViZwdXUV8a/9fr9er6/9p3Ao16bUaQKr2dZms7kaWslKygZ1pSJRrG3bKUd2hTZ9LVw7NzgWKS9ABtVCEwSyAKQRjIZTXhstmaxrDDqdjpTjtNvt6ADI87ydnZ3VUNU0zfAHO52OrFh2NZl9dna29WYJkrLiu6MGg4HELVDBrsRVWew+TIBBtdAEgSxQCVtrUtMXvfm+L3iQfOocCiTrWFbWNf37+/utt+l0Oq1Wayk5upjN7XQ6UtYTVN8u8jyv1Wot/WXKpKx4FJu+KHbJ2rL1rOuqxTGoFpogkAUqYXd3N+u7EL/UeHJykulKimg0GmVXcSFr11ej0RAJpMbjca1Wa7VaYd3q6vas9LFsWH27dNerRx4MBkv3LngXglGsbdtZFMWuvb4h5UuglEsiUoqRgPQIZAH8JWWsI36pkZ1ea/348SO7g8va9RUWvG41Ho+bzWa9Xg8i2qUwvd/vr2ZPpSxmNUpeTZSKhNGCUazjOKPRKLfL/XwJBJYQyAKVIPJBm3L3huClRnZ6bWKa5mQyyejg4/FYvDlaBNM0Y3Va8DwviGhXy07G4/Gm/WHii1l7Oq3GsnGTsoJR7GAwyG6ux9pCnRwurQiiAxc0QSALVMXWCFK8edZagpcav3z5kuZeyq3RaCyFXBJdXl5KOU6v15P1bcTzvHq9nibC3lS2uxTLxkrKikSxQY8tuUWxS2tY+/ea7PQK0IELOiCQBfCXTbukBQlmaEpwbdR13Xq93u12s/ggb7fbGTWX9TxPSlLWENv1JcjzvGazmbiVQUSD26VYdjUpu/bRCPrFRt+pxB5bscja6SVrtyUduKCDP37//q16DQDysHVAfEZz4ZfM5/Nkd7F0d8Efwo/S8JJrPuHFzs5fWQDLsr58+XJxcSH3fsUnSMViWdZ0OpVyqOFwKKuxV8C27dvb2wQPY7fbjSgVcBwnvPofPmshy7IODw8PDg729/ff3t5eX1+jXyOGYQwGg+wSsSHXdZvNZkZ3vfWtQNDiYwsoo3pGLoCcrI6elzg/XXCA+/n5ebKDPz8/39zcnJ+fi0y6Pzo6Ojo6Oj8/f3x8fH5+TvxLRVhdxtHR0ePj4+fnp5TjCz6eCTw+PkpZ4e/fv8/Pz3VY3tbHKjzrtr4Eoh0dHWV0Oq16fHxcXYCse0/5OIRubm6krAdIg0AWqIq1H41Ln9OJD/78/CzyyRfrk/j5+Vkwct3q6Ojo5uZGYhQSEQoEAXT6uxB8SBM8FOnXFsoilk0QL25dRhjLJl5Vsu9gia09wWR9TZL1rOX8mABrEcgCVSESGCU++NYoWfz4Qfya+kN2o/Pz8/QRrciDmf6OZGXOlkhMyv5el5yW4vz8XDxuEzn9ggg+2UOaWyI2tPoSkPgNRNZ5JfdLEZAMm72AqhBp3JN495LIRjGRPUy+7zebTSkFfJsE3aB2dnbS7NYSeTDDRqqJt1hJ7A+wSG5t63Q6zWKR4VQFkedIpHI06JAQdxkZDTvYKtNxAwzlQpkQyAJVkUMr2WirM0VXxW1Tmka/3xcPlZZs6mC6yvO8u7u7+Kv7S0ZTEhJ3CVgro1jWWDckbBOR08bzPPGxXoZhDAaDPIcdRNOwbx2tZKEDAlmgQrZGG+LTuZZszfHYti0YEPR6vTwHygehUoLATsqcz61M08yis+y3b9/kHnA6nWb3rIW57eFwuOlbh9y2bkEiNofuBJusxoj7+/tKVhKNVrJQjkAWqJCtsVd21xzFR5sahjEajXLLywY6nY7I2NJFp6enGS1mSbvdlh4jep4nNylrZP+seZ7X6XRqtdraJr4RDWVjsSxrMpmoTcSujQ739vbyXwmgPwJZoEK2NkJPXJkX/YOO48QNC3q93mQyyXOebb/fjxXbHR8fZ7eYJYn7+0aQnpQ1DKPX62U3mSwUVAjUarWdnZ1Wq9XtdoPCg/QX3x3HmU6n+VfELllb4SNxVZkW4AI5I5AFKmTr1cmMmvAn65reaDSm0+lgMMgtnO10OuKXSsVDcylxw2QySX+QRRIHfS1qt9uz2Sy3p2w8Hvf7/WD3Xqz61yVBLYEm7f0TV/jkj+FeUI5AFqgQkauT0oveUo4zbbfbQTibT+Hsw8OD+I3zTBg3Gg3pF+4vLy/lHjBgmmbwlGVxcOls21ZeS7BktcJH7snPJi2UCYEsUCEiTaPkplgGg4GUS6Ltdns0Gs3n88lk4jhOdhFkmqxe1qR348ooKRtot9vz+TznWudYwnJY5bUES1ZT+FuLglR5f39XvQRU3Z+qFwAgPyI5p58/f8r6XHccR/q+70aj0Wg0gkvAQfL44+Mj+DQNe9mGCa0wIIiVgnJdV25kIzEBdn9/32w2ZR3NMIy7u7tMw7her3dxcfHw8KDVNwTbtr9+/apb/BoqSssCQAuqJzIAyNXWOUzJpvWsHla3Oeyfn5+fn5+Pj49bx4aJD74SH2ol8ReRPu5L1uBTkZVnNAZMXKyBYUp8fn6uLlviaLG1x09M7pQ4IAFKC4Bq2bqzO1n6s8mmUwAAIABJREFUcKmx12Aw0GTfTMg0TdM0wxKFiD1kT09POa8tFukFBrHKgtPo9XrT6XQymeTZJzhgWdZgMJjNZlrVwooTKQoCqolAFqgWkWuUaeomlXeSFxTuIVv9J/EmA6o2zaTcP7ck54v+jUYj/C6RdURrWZbjOLPZbDqdttvtQoSwv379Wv1LiSuXWwQvMpsayBQ1skC1iDQueH9/j1s+eHp6enBwcHFxkV2sMBwOw1zpplgzSAwHO2P29/f39vZ2d3cjltRut9vtdqvVGo/HcdcTK9z3fV/iIxN0MJAYgA6Hw/y/ewQPvmEYruv+/Pnz9fX15eUl/XcDy7IODw9PT0+Pj48LEbkuWQ0N5Sbg5W7PongXyhHIAtUiEqE+PT3FDWtyCIOOj487nU70bTaFQbZtR0Q2o9FoOByGBxeMpdQ2++z1et+/f5eVEv727ZvCJHqwgS/4s+/7we69p6en4OtK9O8YhK0HBwfB9xZt92+JW+29lc8wZKCgCGSByrEsKzo40HPwj2mak8kk2Z798Xgc5Fwty7q6uloN2trt9vHx8fX1tXhq9vv37wlWIpHEDgZBHy4dosCglLnRaKw+R2GH4yLmWcVl/eqjGAAlQ40sUDlbEzye50kfiyBFo9FIWVXpeV6n06nX66u/oGmao9FIcJCY7/vKu8rLHZFwd3cn61AZMf+meiHZWj2vTk9PJR5/NeMLFBqBLFA5Ip+La3ec6GA0GqUvGfQ8r1arrS1yDTaBbT1Cbjv9o0nsYJCgSng4HNb/1mq1hsOhnt9/CiSHB1DP6y1AYgSyQOWI7PfSuQWVrD37aa7LK68rCEnsYDAcDmPduNPpeH8bj8edTqdWq7VareymhZXe2pYCx8fHEu9C7pUEkTcTIFMEskDliJRC6py2aTQaa9tmJdDtdhP8lA51BSGJBQbfvn0TvKXrups23o3H42az2Wq1yM4mkPUOQp4UlA+BLFBFW69Ha1smG2i321Kit36/n+DXTFBXkGllp6wCA/En/fLyMvoG4/F4U/EGIqwtYNW2iSygAwJZoIq2zvcyNC6TDfR6PSnt9BP8mjlPEBDx48cPKce5vr7eeptutyuYkG42m7HKFbB6JUTnJrIGI8egAQJZoIpOTk623kbnMtnAaDRKH8uKX08P6JllNE1TSrmFyJavWHF8p9NJVr9RTavfEOQ2kaX3FsqHQBaoIpE8SoJt7PkbjUYpawziVrsmaFMlN6m2SbvdlpKijs6hJohK+/0+sayIHIp56L2F8iGQBarINE2R6ErP7OOSXq+XMhkpHkD4vp8gvhcp5JBiNBqlP0h0Jj5ZuwZiWRFrC1iDecuySN/EWfq2vtAfgSxQUSLRlf5N8gPtdns2myVOfIrvgElWN5znPPrJZJLyCOPxeFNk77pu4nYN/X6fetloa1sWyD155HbbyOdSAxCNQBaoKJEPSJ2bcC0xTXM6nQrO5VoivgMmbkFtIM9em1K6cW1qy5Dyi02n0ylEjl8rEk8eHnyUEoEsUFEiXdY1b8K1KpjLlSyc3Spx+1iRxr0Spe/nsKl+IH3ZdLPZLNYZlae1D7vEtgDSWxbI3YgGJEMgC1SUYJmsJrNYYwnC2dls5jiOyO8ouJU72UMhZQNWXCmLZT3PW83eySoMODs7k3Kc8sl6yob0PiRy63eBZP5UvQAAynz58mXrZ+f37997vV4+65HLNM1erxcs3nXd9/f3t7e3YNf2YsmE53mCZYjJ2seenp4m+Kn0JpNJmhm8P3/+XEokywqDctv6ViybEtUSd1NJrxTKs/gb2OSP379/q14DADVc1xWJdSaTSc4XxzUk+Fitms/n0hcjaDgcbhokK2Jx5b7v12q19EuyLGs6naY/TvmsPcHkPlw7O5KvwfLOAB1QWgBUl+CHUNbz3wsh2T4nKXN0E0s5yHexukBWhYmsCWTlI72AdUkWO70Y6wUdEMgClSZSwZmsdWjJJNvnpLwqI83Gr8XYXcpU3slkQtvRTdYWakvcTZXF11GeTeiAQBaoNJEKzrVbfyol2a8vZWZseqPRKFkPhzB2lzLLgMvQ0dbO3JK4m0r6TC+ayEITbPYCKk2kCZexbutPpezu7i5GpYvJsyA+CAOO/f39vb293d1drZJVP378ODs7S7ApPojg06djB4NBlc8fEVlPhJZ+fHpvQRNs9gKqrl6vi4Q4CjctIT1Zu7USGAwG7XZbyV0XyNqdWLIeusRbFSM4jqO8cgYwKC0AINgOifmihWaa5mw2y/9+iWJFbKpdkTXWK4sCWXpvQRMEskDVnZyciNws2XRW6MM0zclkkuc9EsUKyrplQRb7NfMcvAxEIJAFqk6weLFw42qxqtFo5JaXJYoVt2m2nKz+VlnMDKPoGZogkAUg2u60iONqsSSoMch6y/lkMiGKFSe9pcCiLFqO0LIA+iCQBSBaXSClmSiUM03zx48fifvLRrMsazabka6LZdPwWCm9L5LN8ohGywLog0AWQIyrhGz5KgfTNEejkfTBY7ZtT6dTrVqPFZesrOemKDkNkf7TQD4IZAEYhnB1AVu+yqTX600mE1kB02AwGI1GUg5VKb7vZ1HDGnBdN4uDC/afBnJAIAvAMISrC5jyVTKNRmM6naZMzdq2PZ/PKYqVS8rl+ywabxkMp4VOCGQBGIZhNBoNwcxcFiV3UKvX681mswThrG3bk8mERGwaHx8f2R08i8ZbGVVXA8kQyAL4i+BkhPF4TB+u8jFNs9frzefzwWCw9SuNZVmO48xms9FoxL6ulDYlTcO5x4llVLSQfmGARH+qXgAAXVxcXAj2JXh4eGA6ZVm12+12u+37/sfHRxBjhc2hDg4O9vf3j4+PubKcg/SjszLqlydYhgTk44/fv3+rXgMAXdTrdcEUzmw2I5oB0tv0oks/UUL85RzLfD6XfkwgMUoLAPzj6upK8JYMRwAylXIGbEb9CiiQhW7IyAL4l50d0e+3JGaA9Da94lJe9Gi1WuPxOPGPb8LkYeiGjCyAfxHPuHS73UxXApRedvsms4hiDTrIQj8EsgD+5fb2VvCWTKwFUorovZUmHZvRBD7LsqiMh24IZAH8i2ma4qOeSMoCGspoAp9ghz4gTwSyAJaJb/nq9/v0lAUSe39/X/v3aeYGZzfzlsZb0BCBLIBlsTZz0L4ASOzt7U36Ma+vr6UfM8DwC2iIQBbAGuLTSknKAomFwyaWHB4eJj5mRtu8aLwFPRHIAlgj1uCu7DJAAGLJrmz969evGR0ZSINAFsB64knZ8Xjsum6miwFK6eXlZe3fHxwcJDvg9+/fUywnCnUF0BOBLID1Li4uxG98eXmZ3UqAqtnf30/wU8PhMKNtXtQVQFt/ql4AisT3/Y+Pj/f397e3t6C0azGdEBR1HRwc7O/v7+3t7e7u0nGw0EzTtG1bsN7O87zhcMjIHyAWuXFnRl23DOoKoDFG1GIL13Xf39+fnp4SbCCwLOvw8PD09PT4+Jigtoh836/VauK3Z2gtEMum+bSTySTupfzhcNjpdGQsag1e2tAWpQVYz3XdVqtVr9ebzWan00m2DdbzvPF43Ol0arVaq9XKaNgMshMkZcVvz3wEQJzcdh/ZpWPFy+WB/JGRxb+4rnt3d5dR95aA4zgXFxckaIsiblI2QSYJqKaIF9dsNov1JplpOjbuYoA8kZHFX7rdbpB/zTSKNQyj3+/XajVSd0URNynLri9A0MfHx6Z/ihs4ZpeOtSyLKBY6I5CtOt/3W63Wzs5Ov9/PaLvrWv1+v16v07OpEG5vb8VvHOz6ym4xAJZk16zAiDOwGlCC0oLqyqGKQIRt26PRSO0asFWr1Yp1qnAtEthqUz2AZVnT6VT8OJt2jEnBNi9ojoxsFbmum08VgYjxeLyzs0NqVnOxkrIGs76AvGRapkX7WOiPQLZagl4EzWYzzyoCEc1mk6pZnZmmGWvn8ng8psAAiPb29rb274Oe3CJ83+/3+/JWtCzuN1ggfwSyVRHUwmqShV2r3++3Wi3Vq8BGsQZ9GYbR6XTkdhcCsCTTSx9s80IhEMhWQrfbrdVq2oawofF4XK/XiX70FDcpaxjG2dlZRosBSuzg4EDkZq7rZvqufn9/n93BAVkIZEtuOBwGHQlUL0SU53m1Wo1YVk+9Xi/W7T3Po2IE2CQY9L1qf39f5MczbXVnWRYNoVEIBLIlt6kGS3PEstoaDAaxbt/v99nJB6y1KfO6t7e39We73W6mWx3ouoWioP1WycUdy6QVWjjpqV6vx/oEjdtLCKiITV3tto7Hy+GNna5bKAoysiWXoK5RH+Rl9fTjx49Yt/c8j218gLjd3d3oG2RdfV7cTw1UEIFs+cWta9QKsayGEnw7ohsXIEvWRQVG/BYlgEIEspVQ6K/X7HzXUIJvR51Oh2JZQERESZXrullv3nUch5ouFAiBbCX0ej3LsvK/X8uyZrNZyjDa87x6vS5rSZAl7q4vwzCazSb5dSBa9Ht1pp0KAqRjUSwEslWRf0fAYIuPaZq9Xm8+n6cJZymy1FC73U4wvpL8OpBYq9XKuqiAdCwKh64FFeL7/q9fv/b29t7f3xfbu4QbCz4+PprNpqy7W+054Pv+2dlZ4jdix3EKXe9bPsm2Ttu2PRqNslgPUCzdbne1TmDTC2Q4HHY6nayXRK8YFM6fqheA/Jim2W63DcPIoc31YDBYfTc0TXM6nSZ+O+73+ycnJ/To1odpmoPBIO6zGWz8Ck5FAEvWNpf1fT+HKJZ0LIqI0gL84+PjQ8pxHMeJCFPa7fZsNktWs0uRpW7a7XaCp5KNX8Ama8d65dAO3LIsLnmhiAhk8Y/39/f0B7Fte+u7YZCaTVY1S5GlbuK2lQ00m01iWVSc4CjafHa7MsoLBUUgi388PT2lPEKs8sderzeZTOLeBRu/dBMUGCT4QfLrqLi1o2iX/jKHrrGGYdi2TbUPCopAFv94eXlJ8+OO48TdxNNoNBKUGdBdXzfJCgwM8uuotrUTvBb/cu1usCzc3t7mcC9AFuhagH/s7CT5YmPb9unpaZpv88m6GbC7ViuJh78HbdqkrwcohNV33fl8HvwhnzYFhmEMBgPSsSguMrL4S9yCRdu2B4PBfD4fjUYp3wSDktm4Kb3r6+s0dwq5EhcYUCuCKtv0vue6bj5RrGVZRLEoNAJZ/OXu7k7kZrZtTyYTKfHrkrixLAUGukk2IsEwjPF4TCyLajo8PFz9S9d1Jbb0jpZssyagDwJZ/GU8Hm/6J8uyHMcJ49fsOrlOp9NYkVCn02G3kFZGo1GyYlliWVTTUtdY27Z9388til3b8BsoFgJZGIZhrE1tWpY1GAxms9l0Ou31evlMIogbCbFbSDeJhyETy6KCTk5OFv/35eUlh5axAToVoBzY7AXDMIx6vR7utbIs6+rq6vj4WOE39cX1bMVOBd2k2aTCAFtUSuJdkimxyRKlQSCLv8IOHeLXUNw+BnQw0E2r1YooVonGRywqJVm7mJR4z0RpUFoA4+3tbTAYTKfTdrutyVubaZqxtiDQwUA3iYtlDcPwPK9er1P9jIpI/EpJbDKZaPJWD6RHIAuj1+tpeGk+VjsnOhhoKHGxrGEYnuednZ0Ry6IKvnz5kufdOY6Tz4YHIB8EstBXu912HEfwxvn0XIS4RqORrLNswPO8Wq1GLIvS29/fz+2+bNvu9Xq53R2QAwJZaK3X64k35GLPu25ifRVZq1arxR3VARTL3t5ePnfETkqUEpu9oLtYu3rZwaChNBu/AjSmQLnlsN+LPZQoKzKy0J1pmpPJRPDGtJXVUJqNX4FOp9PtdmWtB9BKDue2ZVlM8EJZkZFFMXS73X6/L3JLsncaktIskwujKJ/01ytEcKkKJUYgi8IQn5Iwn8+zXgzikjI+Pkgs8ZGMEnBd9/LyUrxbdmJEsSg3SgtQGOLtnLgMraGUTQwCQSsDtn+h6FqtVrPZzCGKpWUsSu//+7//+z/VawCE1Gq1//znPyJBjOu6nU7nv/7rv3JYFcT9z//8j+AzGG04HP7nP//53//9XymrAvLkuu5///d//7//9/9yuK/JZELLWJQepQUoGMECA+optSWrKJAyAxROPhWxAaJYVASBLApGvNSS93FtSfw451lGIQyHwzyHtvC6QHVQI4uCaTQagj32Ly8vs14MkknfkCvUbDYpiYbOfN9vtVp5RrGz2YwoFtVBRhaFJNg/nFZc2vJ9/+zsTNZmF8oMoKecE7G8EFBBBLIoJPGPB1pxaUtKc9lFjuMwRx6a8H3/+vo6t4pYg9ldqCpKC1BI7Xbbtm2RW3LdWVumac5mM4kH7Pf79Xrd932JxwQSGA6HtVqNKBbIARlZFJV4Po9+4DqTMihhCSUlUCX/RKxBkxZUGxlZFJVpmoJJ2evr66wXg8QajcZkMpF7zE6nU6/XmZuAnOWfiDUMw3EcolhUGRlZFJvgri+a0Wgui7ysQdUs8iJ386I43tkAMrIoNsFWXHd3d1mvBGlkkZc1/q6aHQ6H0o8MhLrdbq1WyzmKtSyLNluAQUYWJSA464vUhf4yyssatCVCNlQlYimKBUJkZFF4V1dXIjdjPoL+Go3GYDDI4sie59VqtVarlcXBUU1KErEGRbHAv5GRRRkIJmXZzF4IgnXPiXEaICXXdS8vL/MPYQ2uLAEryMiiDO7v70VulueIHSSTQ9/fTqezs7ND4SwSCObNNpvN/KNYimKBtQhkUQaNRsOyLJFbMh9BZ77v9/v9fO6LFl2IS0l3rYDjONPplCJvYBWlBSgJ8X1CzEfQVqvVyj9KsCzr/v6eRBciKKwlMCgnACKRkUVJNBoN5iMUmuu6SnJdnuc1m026dGEthbUEhmHYtj2fz4ligQhkZFEe4klZMhwaEtyxlynLsq6urtgKhkC3282t1mUVuxIBEWRkUR7iSVnmI+im2+0qj2INw/A8L6idpZa64obD4c7OjqooNtjXRRQLiCAji1Lxfb9Wq4nckqSsPrKbg5CS4zgXFxdUVFeK2nJYg7nKQEwEsigbwQ1DlmVNp9Mc1oOtdCgqiGDb9tevX/naU3qu697d3Skp1A4wfw5IgEAWZSOelKUETQdKOhUkYFnWly9fSNCWkvIQ1iARCyRFIIsSEo+NaMWl1nA4TDylwrKsw8PDg4OD19fXl5eX3HK6JGjLRIcQlkQskAaBLEpIPClr2zZTy1VJXBq79lnzff/s7CzPEgUqaAtNhxDW4LoQkBqBLMpJPCnLri8lxL9sLIn47qFk0xglB4UzHA6/ffumvCzbtu3b21tOGyAlAlmUk3icxK6v/KXJns7n84h/VVhxG/SgPT4+JjTRk+/7Dw8PCvvCLiIRC8hCH1mUk2magj1lPc9jpFPOEkexk8kk+ganp6fRN3AcR/DEiCvoQVur1YI2tL7vZ3EvSMB13VarVavVdIhibdumRywgERlZlFasi9fReT7IkiYXK5LEin7Sw+z7zk4e3+GD7WjsDFNFkyrYkGVZ9/f3nAyAXASyKDPxC830vslBmihWvAIkIkgNm1TkX00blNKenJwQx2RNt/g1wDsMkBECWZRZrHiFXV+ZShk7ijdK2zReYSmSUDhOLKim3dvb43yTxff9X79+PT096Ra/GnTXAjJGIIuSE0/KsusrO2n6xRoxd8ZsesZXQ2Hf96+vr9WGPrZtHxwckKlNIAxe8+wiHBebuoCsEcii5GJVyvKpk4WUnQTi9vpde3cR31KCzezfv39XHgwFNbWnp6e0PljL9/2Pj4/393c9M69L6K4F5INAFuUXK5Bi1pdEruteXl6mCRATpMnXPt0i0bDruj9//tQhog2Eo8tOTk52d3creFoGOde3t7ech7elxKYuIE8Esii/WElZZn3J0u1203c7SvC9InEgG9K24DIMbff39/f29soU3YbZ1sKFrUvY1AXkjEAWlRArKUuBQUpSJicl3iKzdrNXsvBC4XgFcWF0axhGGOAahqFbjBs01g2iVcMwih6wrqKWAFDiT9ULAPJwe3srHpF0Oh2KFJNJX0sQ0GGjd7fb1T+KNQzD87xND7hlWcEfDg8PDcMIg13DMPb29oJ/CqLeRZsedt/3TdNcHPTw8fER/CGITQ3DeHt7Mwzj9fXVMIyXl5dwhTF/p+Lh2y+gCoEsKiEY9CUel1xfX1NgEIvEDgBZRLFBaCWuELnYrcIIsgqhpCrUEgBqMaIWVXF7eyt+4/F4zNxaQb7vB/M/ZUWx0+lUbS62HFEssmZZ1mQyIYoF1CKQRVUESVnx23c6ncWrqFglN4TVRL1eL9Ovg4wMBoPpdEprAkA5NnuhQmK1LzAYkbBZplNA5/N5mh9fO6JW8KncNBUMCLGpC9AKGVlUSNykrOd53W43u/UU0XA4rNfrzWYzu7SlqqIOolhEC2oJRqMRUSygDzKyqJa4SVnDMCaTCRcQg/FX6fvCikjZyndtRtaITPT6vn92dkYUiwhs6gL0RCCLyknQqD/lxe5Cy7SKYJPE89UivqhsOiZRLKIxqQvQGaUFqJxkjfGzWInOXNftdrs7OzuZVhFs8vDwIP2YYdPTRVKiWMuybNseDAaxCldQCGzqAjRHH1lUkeM4sZKy4/G42+1W4cJiUELw/ft3tRnKfr9/cXGRICm7NlrdJEGdSci27dPT09XBGVKCfsdxLi4uFv8mmESw+N/wnxanEnQ6HfFjLgkPu/Qbbbrf8N53d3dltRDWCpu6gEIgkEUV9Xq9uLFav9/f398v6/AeTeLXRQ8PD3K/Ofz8+XMxr5Y4io2Ib4K5Vunt7++vHj/4m8X/Lv69sTBea5VgfefaX2rT/Ub8SAkwqQsoCkoLUFFXV1dxf6TT6bium8ViVPF9v9vt1uv1Wq3W7/f1iWINw+j3+wn6+EYEc4vDvVzXTRbFOo4TsWk9mP6qytPT09q/t20764sJZUrH2rY9m82IYoGiIJBFRbXb7XASvbhms1mCKQlB/aue8eui6+vruD8SkRN9eXkJ/jAcDpvNZoL15BARJub7/tpo0rKsrIctl+AVERoMBnTXAoqF0gJU1/39fYKA5uzs/2/v/nXb1pIwgPMK+xqCDNiwqxM9gaDChQEj7hjWhpo0SRGkY1gK6gwXSZOGYS2osxFAhQqFTyCosmEDVvgezha8y1Uo8nDOX1LU9ysWdxNZomVf3E/DOTNv93RLQhzH8/m8Uf0DfLPZLI5jvedsoijiNJJyWEiEKhaLReGff/v2ra6XFsIYOzs7Oz09PTk5OT4+dhzn6Ogobf99fn5+enp6fHx8eHgw96vLGLu/v0eEBdg7CLJwuAaDgeu6ondF1+t1v9/foyxby/wsXT58+CD0Vm/3D+Ss12vP86Tfh/v7+8rHpAmsFre3t7t/6Pu+heP2ZS0NlRhjV1dXFxcXR0dHnPbcXGfzYrG4vb3Vm2gxIxZgj/0BOGC/f//+R8q7d+/qvnae379///jx4927d3LfXaP8+PGD/o2/efPGxDX8+vWL8uq/fv3S8nJfvnwR/XHvPsmbN2+EnkSaxHv+5csX4lta5vfv31++fFF/q9+8eaN4JQBQL/TIwkHrdrthGEp84Ww2a+Bw2SRJ0hWyvV5vNBrtaRU2p7DWWMbErWf6arejoyPtr05ReHPfQlOB4zhJktDfc8ZYGIavr6/j8VixVNztdsfj8Wazkeh0z7iuixmxAPsOQRYOndypL6dJWTaXXy23wDLGVMJEpfV6HUUR5ZEmTh3VsqD47u5O6PG7N/dd17Vz2cTVFa7rLpfL1WqldxpAt9u9urqS+9r0XJfGiwGAWmBFLYATx7HcMXbHcRhjdfXLGuoX5Ev7GtMTOdutjSrtpxSULcEqP8dCEim209FTHaBvRS4ciGstf/f7ff6vn+u6Hz9+NHQxcsOAsXIWoFXq7m0AaASVfrs3b978/v3b5tVa7n998+ZNZVOj6WugtI3++PFD18tJ/0x1XQD91Xe/a2sN3PwWcwvtpxLtuQ3vbgcAUQiyAP9SOSdk58jIr1+/LOfXHz9+UBKVrkNOfJWXoevNUck6Wi7gH5HzXru/t9ZOL3E+OYieV5Mg8eHTwlUBgGUIsgD/Uk9jQufr6dIRBIbO4xf68uWLUD1Sy/nxSpVvr5a3SPGHqH4BGcrL7f7SWhtW8KfkDX/37p2FGxQS80YM/esJAPVCkAX4P/WSnt6Sz+/fv+2XYGt534iXx3+v1F9C/b6z+jVkKL9Lu++8tbhW+IZbe3XRDy2YsQXQVgiyAH9Rr+ppaZn99euXzRKsdIRNWbtOThzR0t7QqCD7T1X8KoyS1tq1cxnaZqe4aDO05RZ2ALAJ47cA/qI+fXO9Xvd6vSAI5L48HaQ1HA6tzSIIw1BlLhJxNpYWnEGt8/lc/fkfHh7Un0Sj4XDI+UX6/Plz7k8YY9aWrG4PqUgHstp56SRJ6EuGGWObzQaLZwFaDEEW4C+DwcD3ffXnmUwm/X4/jmP6l6QR1uYgWN/3X19fFUd7Sm8oFbVcLjmJhLOcNuW6buW8W8sjeCkmk0mn0/E8L/e7lCTJ7ryzT58+2bmq7XjNGLM5kPXt27fER6aj8ZBiAVqu7pIwQBNpvK1POfti+SzXP1rHLNi52sr3sPJJ/tB6eRXfFh3fLs+7d+/SJpDC78XaPfTtF7U5CoB+rNDmoTcAqBEqsgAFNO44mM1maadB4d6pOI4tV2Edx/F9X9dmTqGSsxxKXa3yMtJFxKenp5Uvp6VFwZzZbDYajTqdzm451lpfQa7b4eLiwsKLOo6TJMlkMqE8ssY1JQBgGYIsQLHlcqnx2SaTSa/X275BHMex53k2e2Gd/7UMjsdjXU9oOvalzZeKl8EYS9snTk5OKp9KdD3sNhM7cunOzs4svMpumrS2IovYVIAUC3BQEGQBiulqlt02m82Gw2G/30+Pcxnd6borLcTqLdoRK2RyfN8nNl/y02d2gO/8/LzyqdapIUZwAAAfwUlEQVTrtXSZ+eXlRe4Ltbi8vLTwKrk0Wdl2rEsQBJSPfEixAIfmP3VfAEBzjcfjx8dH7XHT/okiQ8vljfYVLJdL4gUnScJ5S33fz56HGOLn87nce/X8/CzxVbpQYrqi3TRZVxm4zP39vemLAYBGQUUWgGc6nVqrORmS3p03cf/369ev2p/T+V//A/2CF4sF528l+iiky8xPT09yX6iF6QbZKIp235laysBlMGkL4AAhyAJUWK1W+5tlwzA0NxrJRGuExERSzvyv9IzXNuKPUq7YXDkCzBzXdY0+fxzHhdNbj4+Pjb6uQ24q4E9nA4C2QpAFqLaP9yvTuqbijFgOE30F9KbYTOE41VR2xmsb8Va43CE2y03P2ygDGaQlSTIcDgv/irOiQos4jikF8jAMrZ05A4BGQZAFqNbtdjebTd1XIcDCpiXtfQVhGEq0AXD6ClQ+fkjMLqh3ZIG5GVhJkvR6PUNPXunDhw+Vj3Fd19wHNgBoOARZAJI0y+5Fj4HRdoIUpw4qZ7lcymWR29vbwj/3fb8wxxMrl+v1WjSY8lt1TTNUGa1MsUY/LFGaCizvFQOApkGQBaDqdrsN75c13U6Q0Rva6AMKcuI4Lgs66rNyRb9Ha6t6C5kIlHEc81Os0X8XiE0F2Ww1ADhMCLIAYlarlfb5slqYGBNbpqwOKkFoQEFOWXuDlmUWQsFUe4laiIlAGUVRWV9sxujsLUpTwfZsNQA4TAiyAMLG4/HucfgaMcaWy6XGfV18/LmtdGn9WDp5l2VH13W1hJuHhwf6g79//67+itK0B8ogCApnFOSYO2FGbCqw9jsPAI2FIAsg4/r6uiEts2kh1mZdSldou7+/V6kfl13Gzc0N56soW2pTQmFdZbGtOo2BMkmSfr9PnKRLfzNFrwFNBQBAhCALICltma2xNGu5EJvRspZWfepn4WWUnfHKCO0sIJ73iqLI/ra2bboCZRRFvV6P/r0YGiJLWX+gq+4OAPsOQRZAyfX19evrq/2u2TAMLRdiU1EUqT+J9OmuTBAEu39Y171myl14Otd1wzAUKvarL6eN47jf74t+IyZGJRA/FfDr7gBwOBBkATQYj8ebzcb0dqWU7/uvr691Dc5UP+al5YBOYTm2lnvNnudpeR7GWBiGr6+v0+n0+vr606dP9K9VqW2nEXY4HEoUlbWfLEyShBKmK+vuAHA4EGQB9Oh2u9PpdLPZGKrOZkGnxgMu6se8tBRNC7Mj8V6z0BbZl5cX/gP6/b76sALf9zebzWq12v5wol5krRRFkXSEdcwsxf38+TPlYe/fv9f+0gCwpxBkAXTqdrvj8fj19XW5XOr6L73rusvlMhd0aqF+zEt92W8cx4XZkXivWWgWAUcURZ1ORzHWpxF2PB7v1he73S6xu0D0xGGSJEEQdDqd0Wikcv2Xl5fSX1soiiLKpwLXdVGOBYDMf+q+AIB2GgwGaYEwjuP5fH53dycUGhhjV1dXFxcXjTrRonjMS8sd4cLxomEY2gk3cRx//fpVvQrruu7NzQ3/mq+urii/M/TZW1EU3d7e6jqXprdmTGwqcNAdCwB/++fPnz91XwPAoUiS5OXl5fn5+enpKXePO52gdHFx4ThOo8JrJooixVNNr6+vitcQBMFumGaMrVYr4jN0OgK3ocIwPD8/XywWT09Poh9FOHzfp/RXVK6HTbmuy9/Rqit8bxN6zyk8zyOWY7GQFgC2oSILYE+32+12u83MqZUUj3mpN1qU7Syln/EijtPK6B1HkCKmWId8lIo/RLYw+qsTOotWqaxdZJf2fgYA2HfokQWAanEcK9YjP378qHgNhU0FQjMQKg9vmea6rtBZN0r6N7SVgIMxprddm7KNNlV7mzgANA2CLABU+/r1q+IzKNahPc8rTNJCuXA+n6tcgyLGmOht8WYWIPWWYynbaFN2xtsBwH5BkAWACkmSKHZYKu7yDYKg8AJE16oJzd7STiL/UQ5U8ddraa/Xuq6rsSxK3EabamasB4B6IcgCQAX1qVsqoigqzDoSN7h1zd6SIHc7ntImy1+vpXeLrERRmY84ODZlYbYuAOwdBFkAqKB+Wog+IiqHMypBdI+X+jYHFdK34xXvp2vcIuu6rt5JBfQzXo7jMMYwPhYAdiHIAgBPEATERyr2D+yK47gsxUrsuV0sFjouSpL07Xj+UAKnqmpLX6zAF4ah9rlX9DNejuNcXV3pfXUAaAcEWQDgubu7ozzM9/3VaqXxOE4URcPhsOxvJfbc/vz5U+2K5Km8LfwmV0pILYuAYRj6vu+6LmOs8HkYY67rpouRtY8LiKJIqEBufzgDAOwFLEQAgFL0JQibzabb7ZbN8Bedn89/3TAMJXKV0CoEvZbLpfTQhjiOOYGe8saW/VAK91Nko3ZN38cX/XGovIcA0GKoyAJAKeIShGz3bLfbFZ0ksCsIAk6KlTs1Fcex2kUpUWlUVW9y7Xa7hSXhKIoKH5xSfFE+er9KRmOzLwC0CSqyAFCMXwvclqvtFa4bpeynTZLk7du3/DvOcpU5QwuuKNS3uXKKl8SVrYU/Su1rZomIq3dz1PcbA0AroSILAMWISxB838/9yc3Nze7DKtfDRlHU6/X4KdZ1Xbn7y3WlWEfHKSVOI2zlUbDUYDDYfZK6ZjgIjdxKaT9HCACtgSALAAXoSxB2z111u93ddMtZD5skied5lGbcwohcqd6+AvVTSpzhZfQnL5xWVthdYJT6cg0AgG0IsgBQgLgEoawjdjwe56pohethkyQJgqDX61HCTdaJK0p9v64KvSsJpBUWZZ+enixfhkQ51qmveAwAzYcgCwB59MWhnHNXuRUAufWwWYSl3/SXGLmVqrcEqH5KidM/IJSSd4uyxNlqughtQMipbE0BgMOEIAsAeYrl2NT19fV2CTBLMFEU9ft9oQhb+Voc9fYVODrmWHH6B4RS8mAwyI0vsFzpVCmNc1pTAOCQIcgCQB4lYlLGYOWKsp1Op9PpjEYj0fwkN3IrVW9fQdPsNhlbC/oq5VjHcZ6fnzVeDAC0BoIsAPyFeAAoF1IL5Yqy0iivVaj2o0Vavn1O/4BouXd3pqy1gKj4iaLGxWwA0GQIsgDwF8oSBHqJVMvwKely7GKxUHx1RZyBA+rkUnKuKGvnvJdiOdapu9EZABoLQRYA/i+KIsp9f3qJ9P3792pXVDw3ioi4mWwXYywMw4aPL5VLyWWLvozS0uCB814AsAtBFgD+T2851lGOTdIbEBzHieNYtBnXdd3lcvn6+rpara6vr6VbGvTSvp11uyibmyZhgq4GD+IZRAA4KAiyAPAvYvITjXcfP36UvSKlrxWqAvq+v9lsptPpdm4+Pz+XfvUUcfMWX9mB/cvLS7kn7Ha7NovNugKo5WFhALAXEGQB4F/E5CfasSpdUlUpx9KrgK7rbjab8Xi8e3DKcuArU1aRVVm1YLPYrGs/8Hq9RncBAOQgyAKA45CTn9w8V7k4qFKOpY/CnU6nnLP/Rk9rEZVVZFVaDqTPz4nSuwUX3QUAkIMgCwCOQ94dKheAJOp/KuVYh1AFZIxtNpvKb0f69r0FiqsW0k8XWpofOKTP2xVCdwEA5CDIAgC1HOv7vtzzS9wEVynHVlYBXdddrVaUIKhy+94o9Z4H9clolSTO2/Gt1+vaV7UBQKMgyAIA9Y7teDyWe37R2qpiOZZfBXRddzqdEp9K5TKMUu95uLi4yP7XEBNr1bCqDQC2IcgCAOk4jnQ5NiVUQVQpx/KrgEIpNlX7ea/C5VvqLQHz+dwxMNsrY2it2mw2w5EvAMggyAIcOuJxHPXVBkSMMZU66IcPH8r+SiLFOlZuwfMVLt9SrKTGcZx+elFstOUwt1aN2M8NAIcAQRbg0FGO47iuq5h46LfCVVZ5ccqxjDGJFOs4zsnJifT1mFs3oFJJjaJoOBw6ylV2Pr3HvLahKAsAGQRZgINGPI6zvQtKDvFWuGI5ltNAeX9/L/ectZ/3KkzD0p8roigajUbpP5trkNV+zCsHRVkASCHIAhw0zo34jHo5lk5lUD+nKXO5XEp/C7Wf93p4eMj9ifTW3yAIshTrmPzW0gZcc1CUBYAUgizA4SKWzVSOXmWIN+hVBvWXVel831dMbNLnvXYzqBZy0209z9s+1We0r0DXNi8OFGUBwEGQBThklElGivf6hUgXGp3ycixjTHpqWEPsftiQ6Hbo9/u598fc6T07o15nsxlmygIAgizAgSJOR1K517+Nkr1M7KRVOTqWkR7aqt4nWngDXfSjRb/fz10JY8xcu4i1Ua+YKQsACLIAB4q4BEHlXr8QxdJv4b1sxcUKGdN7XDleXl5yfyJat95NsY6mfF/GxPjYshdCURbgwCHIAhwoC0sQhKiMay0bhas+bCGlMoFL0e42BKEG2cIUa7RdxHKypJxWBIAWQ5AFOERNW4Kg+FrbJ/Ezvu9bG7Zgzu42BHqNvDDFOvraRQqZnleQs16vib/MANBKCLIAh8jOEgQ6lZbNshyj8YyXyihZxSlRuSGy9PkJnucVpljGmNF2kbu7O3NPXqjwYwwAHAgEWYCDY3PqFpFKX0FhKNfbFKGyRmu3yVVIboAXsZjqeV5Zo6rR7tgkSbTsQfB9X2jkWRAE6i8KAPvonz9//tR9DQBgFSflZBhjq9VK44smSdLr9cr+drPZyFVk4zhOt63mvL6+SjxbGf7F8y2XS5WG1E7nr3ID5fvi/Hy1/1hztteGSQvD8Pr6uuwnW0b6VwgA9hoqsgCHxfLUrQynMKnSV1A4gEn7GTWVhLR7Wosud3CKMq8gCALOz1d6Ty/Rz58/FZ8hTbGO4wwGA6GiLPYjABwmBFmAw1LX1C3O3XnpKa1lodzmGTWjciG4cghDEAScYRQWTr8pDt7yfX/7F0+oCwKjuAAOE4IswGGhTN1S2bAlQW7hqlNShDM66l/C7tgBuu0CZ+X3xU+xjtbTb4UUc6Tv+7krHAwGQr+KGMUFcIAQZAEOCHFQka7xq9s4rQXn5+dyz1lY/zM6W8qy7ZNe/PJkZYpdLpfaLquEShNF2SZhoROHGMUFcIAQZAEOCKWF0VBFk9NaIPdyZQfVra0iM217AgB/hUFlivV939wGhIxKg2xZ865oURajuAAODYIswKGo65gXn9CBnm2F80otN0VQ5AbB0i0Wi+yfOT+UyhRbVuzUTrpBdrlccj7MiI6BwygugIOCIAtwKOo65sUnN0E2iqLCeaU2Z9+aljXXclYYeJ5X2fRsdHBsRnrvg+u6/GqxaFGW0gUOAK2BIAtwKOo95lXWI3tyciLxbGV3sS3cQLcmKzkXlmOTJOn3+5VF0DAM7bwn2/VjIZSGbBRlAaAMgizAQSCeKLdf0ZQ46VXWI9HAvgJnZzUXUdYgyxhL36K05JkkSRzHQRD0er3KHVqu61qrr8sNZyCuQRadKTuZTBQ3AwPAvvhP3RcAADYULg7I4Z8oao6yHgnpMV4NlBU41+u13FIxxth0OtV6UTyFLcuV6PMxvn37JrTo6/v373Y6gwGgXqjIAhwEykEcuXZVRRIjC8p6JMxVH+2X99RXZJle4pVTWR7eJTQfQ6IoK3o9ALCPEGQB2o84XNP+QiyJkQVlPRLS0w+aSXFFFn8OgHZyQV/0g5PoPA3MlAU4BAiyAO13e3tb+Rhit2LtynokjJaTOdscTFBckWXtgFdG7v25uLgQerxoxZ3yaw8A+w5BFqDltufqc+xLg2lZqVJu+gGRys4qCZSG5jK+79tfCSH3/kikbd/36Q9er9eKHwkAoPkQZAFarpnjY1NnZ2dCj+fcLJbec0shdyRfmnRfgeu6tZxwkujolWsFEe1+UflIAAB7AUEWoOUox8nrGlwlOpqKE5j2oi+CQrqI6LquzTEF2yRGjIl+hkl1u12h31XFVmMAaD4EWYA2I/YV1LUQSzTNlOUS00Fces2sI/49yhURLQ/bypEYWSDdyiL6u4ojXwDthiAL0GaUvgI742ML2yiFKnmcRHJ6eipzTWRySw3kSBQRGWOr1crExVDIjSw4Pj6WeznROVw48gXQbgiyAG1G6SuoZXysBE5fgdGTXo5UxVGORPmQMWZ5ZKwWKp+dhOZwrddrbPkCaDEEWYDWiuOYksBEpyDVhVOqlC7vUSjGIKFqscSpqfv7+3r7gyVmbykO/RU9mJitSQOA9kGQBWit+Xxe+Zh619LSK538I1BHR0c6LqeYtRiUJIloX8Fms6n9lJvl2WQpoa5odBcAtBiCLEBrNaqvoGyCFbHeyQ/lRsOc4uwtetsDcVBaxvL6rjIS74/cyIJtQke+rHWGAIB9CLIA7UScV2B/LW0O8cY0JZQbovjS9LaHyWRCf9rlclljKX2bxEgH9cN5oke+MLsAoK0QZAHaiTivoPaSHvHGdI1FNcWXJsZNoaTVnBQrR8vhPKGbCRLNxwCwFxBkAdqpUX0FHJQb0/wGWcWTQyovrRG9j7NpKVZiNpmWw3lCNxOwGQGgrRBkAVpoX/oKHFrgruU4UYpyYI6DGLKjKCLWfcMwbFSKrVG32xX6DIMhXACthCAL0EKUg/aW+wrKOikpYz5rvC+sstPLIde8ieXYMAxFJ09ZINF6oWvKhNBAWQzhAmglBFmAFqIkvyb0FaQqEwb/5rX6EXgOxVvSlGZQYjm2mSm2Xufn5/QHo00WoJUQZAFaiBK/mrMHobIeyc955vbHqjfIUpIWpRzr+34zU6zc/XpdtwKEugts7hkGAGsQZAHahhi/mtNqye8uqLG18evXr4rPUJnYKOVY3/fH47HilbQVvbsAu2oBWglBFqBtKOeTfN+3cCV0nz9/LvsriQ2ouij2FVRun0qSZDQa8R/TvhSrd8qEUHdBjb9LAGAIgixA21DmADSnryA1m83KqmWVIwsMjZhV7yu4vLzkP4AT31Ou67YsxWon1F2gOIMCABoIQRagbSjBzn5fQWWHYlmqU9wQK029r4Df1RrHMb/i67rudDpVvAbTmlDjpHcX1LgfDgAMQZAFaBXKgqjKW94mVM4WmM1mhUVQygAs7b2PSZKY7isYDof8L29+im0IendBjfvhAMAQBFmAVqHULytveZtAOTNemO0oX6i9LkhZ8Mt3c3PD+VvP8zh/2+4Uq31cmlB3Ac57AbQMgixAq1Bungqdj7FsN+FRqmjaV39NJhOVL3ddlzOvIAgCTrmXMdbiFGsIfSgy1iIAtAyCLEB7UDbTWl7oJWo2m1G6I3L09tEGQaD4DJxybBzHnJTMGFutVoqvfoDoy5brarkGAEMQZAHag3KHvTkLvcqMRqPs/i/xRrDeQzyK5dgwDMs+KsRxzGmNRYqVRu8uwHkvgJZBkAVoD8p0oaYN3irU6/XSfyA2v2o8xKNYjnVdt2xYQWWKvb+/V3npA0f8hIbzXgAtgyAL0B6UalNzFnrx9ft9ocdrOcSTJIlKOZbT3kpJsU1u+Wg++ic0nPcCaBMEWYD2qKw21TJ4S856vfY8j36KS8shnrdv36p8eVlJNYoi/rAtpFh19E9oOO8F0CYIsgAtQdlEVcvgLWmz2axyg2vm58+fii8XRZHKfeflclkYRj3P438Xm83moFLs6empoWcmfk7DeS+ANkGQBWgJSvGyyYO3FCnuL0iShB6ad4VhuFsRjKKo0+nwL6ws/u6Lo6Mj0S+hbLiQQ/ychvNeAG2CIAvQEpV1pnoHb4mOwXddlz7lPiUxtyuj0lTg+37ugFcURf1+vzIZL5fLfWlZ1shcRZb4OQ3nvQDaBEEWoCUq60z1Dt6iLOhK+b6/2Wym0+lqtRLKstLdBZ7nSYcb3/fH43H6z3EcB0HQ6XRGo1HlExYWcQ+BuYosfQgXpQ8HAPYCgixAS1Qmp3oHb1Eqsq7rbjab8XicVY6FsuxsNpM4kO55nkpbwsnJSRAEnud1Op3hcEgcerBbxAUtiJ/WtK+CA4C6IMgCtAElwDW5/scYWy6X0+l0t/lBKMt+//5d6HX522IpRqPRZDIRehLXdbMi7r5rWoMv8dOa+tFAAGgIBFmANqhcHCDab2rZarXi5Gx6lhWaAhsEgeISLwmcWbOgjvhpjd7oAgANhyAL0AaVO72avJmWElJXqxVxuBLxyJfnefZTrFM+a3Z/Ne0zEuX3ZL1eYy0CQDsgyAK0QeUBmto303LOqhMHGkynU0pGqZwVkCRJv99X7CiQs+/DtvYCcSoCcfsxADQcgixAG1TeKpWY92kNfR7TdDr1fb/yYUEQlP1VFEW9Xq+WAUxtHVMgOljNtPfv31MeVnkTAwD2AoIsQBvwk1m9E2RTJycnWp5nPB5XZtnJZLJ74zhJksolW+a4rosxBXYQf9WxFgGgHRBkAfZeZbdfkxtkHfGMOx6PwzDkP2Z7wUGSJEEQ9Hq9WtoJnLYf8DK34EAasU3WwpUAgGkIsgB7r7Lbr/YGWb7KnWS7rq+vl8sl5wHr9TqKorQK2+v1ajnXlfn27VuNr26a6OcQCxMDiLtqsRYBoAUQZAH2XuV09yY0yB4fH+t9wsFgwM+yo9Goxipsxvf9VrbGNhlxVy3aZAFaAEEWYO/xK5pNaJB1uGFaemdpZZatHWOsNbsPymj/iKKOuKsWbbIALYAgC7D3+EGwIYfKDYXpwWCw2WxMPLMW7W4qSDWz3kz5tcc0WYAW+E/dFwAAqvhNh8R+QQsYY4UnbBSbJrvd7nK5HA6HKk9iwn41FSRJkjZbp50qZWX+x8fH09NT6SK6NR8/fqR0lSwWC0yTANhr//z586fuawAAJZ0O79bKZrNpQmuB4zie55VlC/WLjOO4aVn29fW17ksolSTJYrF4enp6fHx8eHiweYSfMbZarUy/SpIkvV6vIRcDAOagIgvQcg1JsY7jXF5elgXZl5cXxescDAZhGKqPic16KxWzXeWAMPviOJ7P54+Pj7UfgLMgbZOt/CGm3QXN+XcEAEQhyALsN36TH+XIizWcs+Tz+Vz9Lvz19fXt7a1QAGWMXV1dnZycnJ+fF6aZ9Ib78/Pzz58/6fmPMdaEG9ZZ2fXu7u4Ax6ZeXV1Rvmt0FwDsNbQWAOw3/i113/cbdWq+3+8XZgtdd3iJDQaMsU+fPpWFV44kSb5//16ZC5fLZV3dsXEcp7HbcsOAENd1b25uTNdB6b8M6C4A2F8IsgD7LYoizv30GhNVoSAIynYT6OooLcvKKdd1P378qP6exHH84cMHuVAeBMHd3d3Z2dnp6enJycnx8fHR0ZFcqkvr8YvFouHJtVAYhkZLocQ2WadJfeQAIApBFmC/8YNs0/4LzSmS6crcZVmZMfbt2ze9sb7wtSq/kbKAxRjbTrfOzvDdtMkhnSeQzkDdr+S6y8QPZRv/U02maTcuAIAOQRZgv3FqnM28Z1qWLVzXnU6n6s9fmOx1Pfmu3LdDfM8bOGOhRuZyJOffjpwmj5gAAA4sRADYb5yJng1ZhZBzdXVV+OeK02Qzu0fKwjA0lGJ3ffr0ifKwdMaC6YvZF5PJpNPpRFGk/ZkvLi6IjwyCQPurA4AFCLIArXV6elr3JRQoyxbr9TqOY+0v5/u+uUbMOI5z1WX6a11fX/u+b+Ci9tVoNPI8T++qLXrTArFwCwBNgyALsN84hUx6OcqmwWBQNhRsPp+rP/92TzBjzFzvY5IkufYA0WFn4/EYWXbbbDbr9Xp6S7P0HwqKsgD7CEEWoLVyR4Wao6y7ID3ApBHxRr+EKIp2D2yVfV8c4/HYdV1NF9USo9Go3+/rKs3SfyiTyURvPRgALECQBWitRs0r2Pb+/fvCP0/XLKk/f1aE46xgkJYkied56ivEMtPptFF7K5pgvV73ej0tJVKh+xJv375Vf0UAsAlTC8Cs7Vzy8vKS/sPz8/PuI9N5Q5ntamJjA1kTdDrFH0ebObIg43le4aIsLQfYs/dE+1F0/rAzlcGoxEFRh0bLfK6yf0cKYRQXwH7BilrQIJvK/vT0lB6iTxs39f6HOatapYfx05NMuYmbiLwZidvcNl1eXhYG2bu7O/UYwRhbr9d6y5z0QU5y7u/vidP7D8p6vR4Oh4qbwNLfB+KDJ5PJyckJltYC7AsEWRC2vX3e5jKh7IUqXzFNMAeed5t50itzfX19e3u7+6PU+OukZfpYHMdfv34tzNx6dbtdobx1UGaz2Ww2833//fv3Ev/ynp2dCb2xadEdWRZgLyDIAkmSJIvFojB5NFB6kcS86+xEXmerz6FRwTetfG+vd+IMkZ3P50dHR1k7R/rPhf9r7oKzV9n9q6Ojo7J44XmedPkt/ZSVPq309LH0t/3nz5/m8mvuR/n4+Lh3C2btm0wmk8lEYslwWfmfA1kWYF+gRxZI0u3wB/4f2u3gm4WkNPimttt8KQFxO+FlfcNpQnX+F1Kz6VqH9uZn+1qdv9/kVPYuOY6TpkBn5y1KE0/6z4U/jvT9T995LWnS9/1cIXz7x1p2nSAh/fW4vLw8Pj4u7Kff7s5fLBZyh/PMLYQDAF0QZEFYYTHJwX+eAaB1tJw2AwBzEGRBs/TeruM4udvfCLsAsKcQZwEaC0EWapNVdtP/uz2Ta/vGsVPUCfrw8HB2dsZZagWV0nP9+GgBQMfveEn7HBrSUg9wIBBkAaBA4QDgzO4k4Kenp5OTk9wnkG2F59L4H0UQsqEJdue4ZcdDs7OhyK8AdUGQBYD9UJaty87JZXJxGfn4kG2n0u1xJc5BDukDaAEEWQCAvN1NuZVl6dwghfQftjM0ejkk7M7IK7yhv/1/sRQQ4KAgyAIA1ClJkm63uxudU5xZvDnPz8/Hx8eF+58tSy8j+1/OI8uGGSOAAgARgiwAAAAA7KVO3RcAAAAAACADQRYAAAAA9hKCLAAAAADspf8C0NgIidM11JQAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "2538b6a8",
   "metadata": {},
   "source": [
    "In this scenario, the batch size is further increased to 64, the block size is increased to 256, and the number of heads is increased to 16. The number of layers is increased to 8, while dropout remains at 0.2.\n",
    "\n",
    "These adjustments aim to explore the impact of larger batch sizes, increased block sizes, and higher numbers of layers and heads. It is important to note that these choices may result in longer runtimes and increased memory requirements.\n",
    "\n",
    "After a grueling `2h 32m 5s`, this run ended with a train loss of `1.2534` and validation loss of `1.5092`.\n",
    "\n",
    "In exchange for much longer runtimes, I was returned something that somewhat actually resembled English.\n",
    "\n",
    "Just imagine this kind of vibe from this conversation:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b0203",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-27T16:49:35.557Z"
    }
   },
   "source": [
    "### Step 3: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b088aac",
   "metadata": {},
   "source": [
    "In conclusion, the process of fine-tuning the nanoGPT model involved iteratively adjusting various hyperparameters to improve the quality of the generated samples. We started with the baseline parameters provided in the repository, which served as our initial benchmark. However, the generated samples from the baseline model still lacked coherence and often contained nonsensical phrases.\n",
    "\n",
    "To address this, we made successive modifications to the hyperparameters, such as increasing the batch size, block size, number of heads, layers, and dropout rate. These adjustments aimed to capture more complex patterns in the data and improve the model's ability to generate coherent English text.\n",
    "\n",
    "The first attempt at fine-tuning resulted in improved loss values, indicating that the model was learning from the data more effectively. However, the generated samples still exhibited limited coherence and naturalness, resembling a language that was unfamiliar with English.\n",
    "\n",
    "In the subsequent iteration, we further increased the batch size, block size, and the number of heads, layers, and dropout rate. This led to a longer training time of 17 minutes and 3 seconds. The generated samples showed some improvement in coherence and resemblance to English conversations, although they still fell short of being truly human-like.\n",
    "\n",
    "Finally, we experimented with an even larger configuration by increasing the batch size to 64, block size to 256, and significantly increasing the number of heads and layers. This resulted in a substantial runtime of 2 hours, 32 minutes, and 5 seconds. The generated samples showed further improvement and started to resemble coherent English text, although they still contained occasional nonsensical phrases and lacked full fluency.\n",
    "\n",
    "Overall, the process of fine-tuning the nanoGPT model involved a trade-off between runtime, model complexity, and the quality of generated samples. While there were notable improvements in the coherence and naturalness of the generated text, achieving truly human-like outputs still remains a challenge. Further fine-tuning and adjustments may be necessary to continue enhancing the model's performance and generate more accurate and fluent language, with more technological resources. Nothing personal with Jojie, she's probably working very, very hard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f66a2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-27T15:06:23.827Z"
    }
   },
   "source": [
    "## Generative AI Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d8ced",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-27T15:08:48.578Z"
    }
   },
   "source": [
    "I used ChatGPT to:\n",
    "- Articulate myself better\n",
    "- Ask for more clarifications on things I wasn't sure of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6c905",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-27T15:13:18.214Z"
    }
   },
   "source": [
    "## References "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab7a70",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-27T15:59:16.062Z"
    }
   },
   "source": [
    "1. Karpathy, A. (2023, January 17). Let's build GPT: from scratch, in code, spelled out [Video file]. Retrieved from https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "2. A beginner’s guide to language models. Built In. (n.d.). https://builtin.com/data-science/beginners-guide-language-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
